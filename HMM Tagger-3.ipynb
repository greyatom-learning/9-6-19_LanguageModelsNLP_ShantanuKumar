{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of Speech Tagging with Hidden Markov Models \n",
    "---\n",
    "### Introduction\n",
    "\n",
    "Part of speech tagging is the process of determining the syntactic category of a word from the words in its surrounding context. It is often used to help disambiguate natural language phrases because it can be done quickly with high accuracy. Tagging can be used for many NLP tasks like determining correct pronunciation during speech synthesis (for example, _dis_-count as a noun vs dis-_count_ as a verb), for information retrieval, and for word sense disambiguation.\n",
    "\n",
    "In this notebook, we'll use the [Pomegranate](http://pomegranate.readthedocs.io/) library to build a hidden Markov model for part of speech tagging using a \"universal\" tagset. Hidden Markov models have been able to achieve [>96% tag accuracy with larger tagsets on realistic text corpora](http://www.coli.uni-saarland.de/~thorsten/publications/Brants-ANLP00.pdf). Hidden Markov models have also been used for speech recognition and speech generation, machine translation, gene recognition for bioinformatics, and human gesture recognition for computer vision, and more. \n",
    "\n",
    "![](_post-hmm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Jupyter \"magic methods\" -- only need to be run once per kernel restart\n",
    "%load_ext autoreload\n",
    "%aimport helpers, tests\n",
    "%autoreload 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import python modules -- this cell needs to be run again if you make changes to any of the files\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "from itertools import chain\n",
    "from collections import Counter, defaultdict\n",
    "from helpers import show_model, Dataset\n",
    "from pomegranate import State, HiddenMarkovModel, DiscreteDistribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and preprocess the dataset\n",
    "---\n",
    "We'll start by reading in a text corpus and splitting it into a training and testing dataset. The data set is a copy of the [Brown corpus](https://en.wikipedia.org/wiki/Brown_Corpus) (originally from the [NLTK](https://www.nltk.org/) library) that has already been pre-processed to only include the [universal tagset](https://arxiv.org/pdf/1104.2086.pdf). You should expect to get slightly higher accuracy using this simplified tagset than the same model would achieve on a larger tagset like the full [Penn treebank tagset](https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html), but the process you'll follow would be the same.\n",
    "\n",
    "Example from the Brown corpus. \n",
    "```\n",
    "b100-38532\n",
    "Perhaps\tADV\n",
    "it\tPRON\n",
    "was\tVERB\n",
    "right\tADJ\n",
    ";\t.\n",
    ";\t.\n",
    "\n",
    "b100-35577\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57340 sentences in the corpus.\n",
      "There are 43005 sentences in the training set.\n",
      "There are 14335 sentences in the testing set.\n"
     ]
    }
   ],
   "source": [
    "data = Dataset(\"tags-universal.txt\", \"brown-universal.txt\", train_test_split=0.75)\n",
    "\n",
    "print(\"There are {} sentences in the corpus.\".format(len(data)))\n",
    "print(\"There are {} sentences in the training set.\".format(len(data.training_set)))\n",
    "print(\"There are {} sentences in the testing set.\".format(len(data.testing_set)))\n",
    "\n",
    "\n",
    "assert len(data) == len(data.training_set) + len(data.testing_set), \\\n",
    "       \"The number of sentences in the training set + testing set should sum to the number of sentences in the corpus\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentences\n",
    "\n",
    "`Dataset.sentences` is a dictionary of all sentences in the training corpus, each keyed to a unique sentence identifier. Each `Sentence` is itself an object with two attributes: a tuple of the words in the sentence named `words` and a tuple of the tag corresponding to each word named `tags`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: b100-28144\n",
      "words:\n",
      "\t('and', 'August', '15', ',', 'November', '15', ',', 'February', '17', ',', 'and', 'May', '15', ',', '(', 'Cranston', ')', '.')\n",
      "tags:\n",
      "\t('CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.')\n"
     ]
    }
   ],
   "source": [
    "key = 'b100-28144'\n",
    "print(\"Sentence: {}\".format(key))\n",
    "print(\"words:\\n\\t{!s}\".format(data.sentences[key].words))\n",
    "print(\"tags:\\n\\t{!s}\".format(data.sentences[key].tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counting Unique Elements\n",
    "\n",
    "You can access the list of unique words (the dataset vocabulary) via `Dataset.vocab` and the unique list of tags via `Dataset.tagset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 1161192 samples of 56057 unique words in the corpus.\n",
      "There are 870604 samples of 49082 unique words in the training set.\n",
      "There are 290588 samples of 28205 unique words in the testing set.\n",
      "There are 6975 words in the test set that are missing in the training set.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are a total of {} samples of {} unique words in the corpus.\"\n",
    "      .format(data.N, len(data.vocab)))\n",
    "print(\"There are {} samples of {} unique words in the training set.\"\n",
    "      .format(data.training_set.N, len(data.training_set.vocab)))\n",
    "print(\"There are {} samples of {} unique words in the testing set.\"\n",
    "      .format(data.testing_set.N, len(data.testing_set.vocab)))\n",
    "print(\"There are {} words in the test set that are missing in the training set.\"\n",
    "      .format(len(data.testing_set.vocab - data.training_set.vocab)))\n",
    "\n",
    "assert data.N == data.training_set.N + data.testing_set.N, \\\n",
    "       \"The number of training + test samples should sum to the total number of samples\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing word and tag Sequences\n",
    "The `Dataset.X` and `Dataset.Y` attributes provide access to ordered collections of matching word and tag sequences for each sentence in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: ('Mr.', 'Podger', 'had', 'thanked', 'him', 'gravely', ',', 'and', 'now', 'he', 'made', 'use', 'of', 'the', 'advice', '.')\n",
      "\n",
      "Labels 1: ('NOUN', 'NOUN', 'VERB', 'VERB', 'PRON', 'ADV', '.', 'CONJ', 'ADV', 'PRON', 'VERB', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
      "\n",
      "Sentence 2: ('But', 'there', 'seemed', 'to', 'be', 'some', 'difference', 'of', 'opinion', 'as', 'to', 'how', 'far', 'the', 'board', 'should', 'go', ',', 'and', 'whose', 'advice', 'it', 'should', 'follow', '.')\n",
      "\n",
      "Labels 2: ('CONJ', 'PRT', 'VERB', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'ADP', 'ADV', 'ADV', 'DET', 'NOUN', 'VERB', 'VERB', '.', 'CONJ', 'DET', 'NOUN', 'PRON', 'VERB', 'VERB', '.')\n",
      "\n",
      "Sentence 3: ('Such', 'an', 'instrument', 'is', 'expected', 'to', 'be', 'especially', 'useful', 'if', 'it', 'could', 'be', 'used', 'to', 'measure', 'the', 'elasticity', 'of', 'heavy', 'pastes', 'such', 'as', 'printing', 'inks', ',', 'paints', ',', 'adhesives', ',', 'molten', 'plastics', ',', 'and', 'bread', 'dough', ',', 'for', 'the', 'elasticity', 'is', 'related', 'to', 'those', 'various', 'properties', 'termed', '``', 'length', \"''\", ',', '``', 'shortness', \"''\", ',', '``', 'spinnability', \"''\", ',', 'etc.', ',', 'which', 'are', 'usually', 'judged', 'by', 'subjective', 'methods', 'at', 'present', '.')\n",
      "\n",
      "Labels 3: ('PRT', 'DET', 'NOUN', 'VERB', 'VERB', 'PRT', 'VERB', 'ADV', 'ADJ', 'ADP', 'PRON', 'VERB', 'VERB', 'VERB', 'PRT', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'NOUN', 'ADJ', 'ADP', 'VERB', 'NOUN', '.', 'NOUN', '.', 'NOUN', '.', 'ADJ', 'NOUN', '.', 'CONJ', 'NOUN', 'NOUN', '.', 'ADP', 'DET', 'NOUN', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', 'VERB', '.', 'NOUN', '.', '.', '.', 'NOUN', '.', '.', '.', 'NOUN', '.', '.', 'ADV', '.', 'DET', 'VERB', 'ADV', 'VERB', 'ADP', 'ADJ', 'NOUN', 'ADP', 'NOUN', '.')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accessing words with Dataset.X and tags with Dataset.Y\n",
    "for i in range(3):\n",
    "    print(\"Sentence {}:\".format(i + 1), data.X[i])\n",
    "    print()\n",
    "    print(\"Labels {}:\".format(i + 1), data.Y[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing (word, tag) Samples\n",
    "The `Dataset.stream()` method returns an iterator that chains together every pair of (word, tag) entries across all sentences in the entire corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stream (word, tag) pairs:\n",
      "\n",
      "\t ('Mr.', 'NOUN')\n",
      "\t ('Podger', 'NOUN')\n",
      "\t ('had', 'VERB')\n",
      "\t ('thanked', 'VERB')\n",
      "\t ('him', 'PRON')\n",
      "\t ('gravely', 'ADV')\n",
      "\t (',', '.')\n",
      "\t ('and', 'CONJ')\n",
      "\t ('now', 'ADV')\n",
      "\t ('he', 'PRON')\n",
      "\t ('made', 'VERB')\n",
      "\t ('use', 'NOUN')\n",
      "\t ('of', 'ADP')\n",
      "\t ('the', 'DET')\n",
      "\t ('advice', 'NOUN')\n",
      "\t ('.', '.')\n",
      "\t ('But', 'CONJ')\n",
      "\t ('there', 'PRT')\n",
      "\t ('seemed', 'VERB')\n",
      "\t ('to', 'PRT')\n",
      "\t ('be', 'VERB')\n",
      "\t ('some', 'DET')\n",
      "\t ('difference', 'NOUN')\n",
      "\t ('of', 'ADP')\n",
      "\t ('opinion', 'NOUN')\n",
      "\t ('as', 'ADP')\n",
      "\t ('to', 'ADP')\n",
      "\t ('how', 'ADV')\n",
      "\t ('far', 'ADV')\n",
      "\t ('the', 'DET')\n",
      "\t ('board', 'NOUN')\n",
      "\t ('should', 'VERB')\n",
      "\t ('go', 'VERB')\n",
      "\t (',', '.')\n",
      "\t ('and', 'CONJ')\n",
      "\t ('whose', 'DET')\n",
      "\t ('advice', 'NOUN')\n",
      "\t ('it', 'PRON')\n",
      "\t ('should', 'VERB')\n",
      "\t ('follow', 'VERB')\n",
      "\t ('.', '.')\n",
      "\t ('Such', 'PRT')\n",
      "\t ('an', 'DET')\n",
      "\t ('instrument', 'NOUN')\n",
      "\t ('is', 'VERB')\n",
      "\t ('expected', 'VERB')\n",
      "\t ('to', 'PRT')\n",
      "\t ('be', 'VERB')\n",
      "\t ('especially', 'ADV')\n",
      "\t ('useful', 'ADJ')\n",
      "\t ('if', 'ADP')\n",
      "\t ('it', 'PRON')\n",
      "\t ('could', 'VERB')\n",
      "\t ('be', 'VERB')\n",
      "\t ('used', 'VERB')\n",
      "\t ('to', 'PRT')\n",
      "\t ('measure', 'VERB')\n",
      "\t ('the', 'DET')\n",
      "\t ('elasticity', 'NOUN')\n",
      "\t ('of', 'ADP')\n",
      "\t ('heavy', 'ADJ')\n",
      "\t ('pastes', 'NOUN')\n",
      "\t ('such', 'ADJ')\n",
      "\t ('as', 'ADP')\n",
      "\t ('printing', 'VERB')\n",
      "\t ('inks', 'NOUN')\n",
      "\t (',', '.')\n",
      "\t ('paints', 'NOUN')\n",
      "\t (',', '.')\n",
      "\t ('adhesives', 'NOUN')\n",
      "\t (',', '.')\n",
      "\t ('molten', 'ADJ')\n",
      "\t ('plastics', 'NOUN')\n",
      "\t (',', '.')\n",
      "\t ('and', 'CONJ')\n",
      "\t ('bread', 'NOUN')\n",
      "\t ('dough', 'NOUN')\n",
      "\t (',', '.')\n",
      "\t ('for', 'ADP')\n",
      "\t ('the', 'DET')\n",
      "\t ('elasticity', 'NOUN')\n",
      "\t ('is', 'VERB')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# use Dataset.stream() (word, tag) samples for the entire corpus\n",
    "print(\"\\nStream (word, tag) pairs:\\n\")\n",
    "for i, pair in enumerate(data.stream()):\n",
    "    print(\"\\t\", pair)\n",
    "    if i > 80: break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For both our baseline tagger and the HMM model we'll build, we need to estimate the frequency of tags & words from the frequency counts of observations in the training corpus. In the next several cells you will complete functions to compute the counts of several sets of counts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a Most Frequent Class tagger\n",
    "---\n",
    "\n",
    "Perhaps the simplest tagger (and a good baseline for tagger performance) is to simply choose the tag most frequently assigned to each word. This \"most frequent class\" tagger inspects each observed word in the sequence and assigns it the label that was most often assigned to that word in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPLEMENTATION: Pair Counts\n",
    "\n",
    "Complete the function below that computes the joint frequency counts for two input sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your emission counts look good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def pair_counts(sequences_A, sequences_B):\n",
    "    \"\"\"Return a dictionary keyed to each unique value in the first sequence list\n",
    "    that counts the number of occurrences of the corresponding value from the\n",
    "    second sequences list.\n",
    "    \n",
    "    For example, if sequences_A is tags and sequences_B is the corresponding\n",
    "    words, then if 1244 sequences contain the word \"time\" tagged as a NOUN, then\n",
    "    you should return a dictionary such that pair_counts[NOUN][time] == 1244\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for x1, sentence in enumerate(sequences_A):\n",
    "        for x2, s_A in enumerate(sentence):\n",
    "            \n",
    "            t = sequences_B[x1][x2]\n",
    "            \n",
    "            if s_A in results and t in results[s_A]:\n",
    "                results[s_A][t] += 1\n",
    "            elif s_A in results:\n",
    "                    results[s_A][t] = 1\n",
    "            else:\n",
    "                results[s_A] = {t:1}\n",
    "\n",
    "    return results\n",
    "    \n",
    "emission_counts = pair_counts(data.training_set.Y, data.training_set.X)\n",
    "\n",
    "#print(len(emission_counts))\n",
    "assert len(emission_counts) == 12, \\\n",
    "       \"There should be 12 tags in your dictionary.\"\n",
    "assert max(emission_counts[\"NOUN\"], key=emission_counts[\"NOUN\"].get) == 'time', \\\n",
    "       \"Hmmm...'time' is expected to be the most common NOUN.\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your emission counts look good!</div>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artists': 33,\n",
       " 'representations': 7,\n",
       " 'figures': 66,\n",
       " 'B.C.': 13,\n",
       " 'reality': 62,\n",
       " 'Plate': 2,\n",
       " 'months': 133,\n",
       " 'defendant': 5,\n",
       " 'world': 514,\n",
       " 'individuals': 52,\n",
       " 'grave': 11,\n",
       " 'fathers': 8,\n",
       " 'mothers': 20,\n",
       " 'graybeards': 1,\n",
       " 'adolescents': 5,\n",
       " 'babies': 7,\n",
       " 'death': 201,\n",
       " 'meaning': 89,\n",
       " 'gentlemen': 17,\n",
       " 'point': 269,\n",
       " 'time': 1198,\n",
       " 'Alleghenies': 1,\n",
       " 'Poconos': 1,\n",
       " 'Pennsylvania': 33,\n",
       " 'Renovo': 1,\n",
       " 'Foliage': 4,\n",
       " 'Festival': 12,\n",
       " 'Oct.': 19,\n",
       " 'doubt': 72,\n",
       " 'Tim': 17,\n",
       " 'Mrs.': 412,\n",
       " 'Buck': 11,\n",
       " \"cowboy's\": 1,\n",
       " 'name': 201,\n",
       " 'cow': 18,\n",
       " 'milk': 35,\n",
       " 'pitcher': 13,\n",
       " 'lure': 4,\n",
       " 'marriage': 68,\n",
       " 'trap': 11,\n",
       " 'domesticity': 1,\n",
       " 'cats': 10,\n",
       " 'energy': 68,\n",
       " 'thermocouple': 2,\n",
       " 'temperature': 97,\n",
       " 'gas': 65,\n",
       " 'ideals': 13,\n",
       " 'country': 253,\n",
       " 'Protestantism': 9,\n",
       " 'stock': 96,\n",
       " 'Matsuo': 23,\n",
       " 'rifle': 49,\n",
       " 'Rousseau': 14,\n",
       " 'Dave': 27,\n",
       " 'Trager': 1,\n",
       " 'showman': 3,\n",
       " 'boss': 12,\n",
       " \"Chicago's\": 5,\n",
       " 'basketball': 7,\n",
       " 'Packers': 1,\n",
       " 'club': 52,\n",
       " 'use': 269,\n",
       " 'season': 70,\n",
       " 'ticket': 8,\n",
       " 'holders': 2,\n",
       " 'Stock': 6,\n",
       " 'Yards': 1,\n",
       " 'Inn': 3,\n",
       " 'living': 17,\n",
       " 'room': 257,\n",
       " 'Frank': 33,\n",
       " 'Graham': 11,\n",
       " 'Journal-American': 1,\n",
       " 'sports': 33,\n",
       " 'columnist': 4,\n",
       " 'Health': 14,\n",
       " 'Serenity': 1,\n",
       " 'one': 348,\n",
       " 'joy': 34,\n",
       " 'something': 308,\n",
       " 'form': 234,\n",
       " 'language': 78,\n",
       " 'incidents': 9,\n",
       " 'pity': 7,\n",
       " 'fear': 68,\n",
       " 'emotions': 35,\n",
       " 'audience': 91,\n",
       " 'domestic': 1,\n",
       " 'Newport': 22,\n",
       " 'year': 496,\n",
       " 'Bethlehem': 1,\n",
       " 'tests': 41,\n",
       " 'changes': 88,\n",
       " 'launderings': 1,\n",
       " 'Mr.': 654,\n",
       " 'Hammarskjold': 13,\n",
       " \"Nations'\": 3,\n",
       " 'leader': 49,\n",
       " 'experts': 27,\n",
       " 'wars': 18,\n",
       " 'pre-emption': 1,\n",
       " 'escalation': 3,\n",
       " 'behavior': 74,\n",
       " 'terms': 119,\n",
       " 'report': 92,\n",
       " 'King': 40,\n",
       " 'Arthur': 35,\n",
       " 'overnighters': 3,\n",
       " 'rooms': 43,\n",
       " 'people': 608,\n",
       " 'Inside': 1,\n",
       " 'pieces': 67,\n",
       " 'coats': 9,\n",
       " 'Creek-Turn': 5,\n",
       " 'bottle': 58,\n",
       " 'antique': 5,\n",
       " 'glaze': 7,\n",
       " 'health': 70,\n",
       " 'money': 204,\n",
       " 'witch': 4,\n",
       " 'doctors': 19,\n",
       " 'gadgets': 5,\n",
       " 'shares': 31,\n",
       " 'June': 76,\n",
       " 'beef': 26,\n",
       " 'vegetables': 13,\n",
       " 'cans': 3,\n",
       " 'summer': 98,\n",
       " 'Washington': 160,\n",
       " 'Feb.': 17,\n",
       " 'supplier': 5,\n",
       " 'convenience': 14,\n",
       " 'transport': 9,\n",
       " 'loads': 8,\n",
       " 'weeks': 106,\n",
       " 'reserve': 15,\n",
       " 'supply': 42,\n",
       " 'weather': 50,\n",
       " 'contingencies': 5,\n",
       " 'way': 659,\n",
       " 'airport': 8,\n",
       " 'Paris': 54,\n",
       " 'Lucy': 35,\n",
       " 'Gloriana': 3,\n",
       " 'girls': 108,\n",
       " 'car': 204,\n",
       " 'carrots': 3,\n",
       " 'winter': 57,\n",
       " 'showdown': 2,\n",
       " 'West': 72,\n",
       " 'Communists': 27,\n",
       " 'power': 234,\n",
       " 'might': 10,\n",
       " 'guerrilla': 10,\n",
       " 'skirmishes': 1,\n",
       " 'mob': 8,\n",
       " 'uprisings': 2,\n",
       " 'streets': 47,\n",
       " 'parliaments': 1,\n",
       " 'meetings': 20,\n",
       " 'conspirators': 2,\n",
       " 'Nations': 35,\n",
       " 'propaganda': 23,\n",
       " 'front': 110,\n",
       " 'conferences': 14,\n",
       " 'level': 155,\n",
       " 'Today': 33,\n",
       " 'industries': 20,\n",
       " 'employees': 48,\n",
       " 'loss': 63,\n",
       " 'growth': 121,\n",
       " 'sawtimber': 3,\n",
       " 'damage': 23,\n",
       " 'agencies': 50,\n",
       " 'States': 315,\n",
       " 'board': 130,\n",
       " 'feet': 224,\n",
       " 'hair': 115,\n",
       " 'faces': 41,\n",
       " 'study': 153,\n",
       " 'lb': 7,\n",
       " 'oxygen': 31,\n",
       " 'hr.': 3,\n",
       " 'hp.': 2,\n",
       " 'Haney': 16,\n",
       " 'B.': 62,\n",
       " 'family': 230,\n",
       " 'attempt': 50,\n",
       " 'client': 14,\n",
       " 'awareness': 24,\n",
       " 'problem': 232,\n",
       " 'absence': 40,\n",
       " 'request': 35,\n",
       " 'assistance': 58,\n",
       " 'bed': 96,\n",
       " 'light': 190,\n",
       " 'Buckley': 5,\n",
       " 'right': 135,\n",
       " \"Gerosa's\": 1,\n",
       " 'successor': 14,\n",
       " '$5000': 4,\n",
       " 'children': 263,\n",
       " 'thing': 258,\n",
       " '90%': 4,\n",
       " 'transportation': 31,\n",
       " 'friends': 110,\n",
       " 'bathroom': 13,\n",
       " 'eyelids': 6,\n",
       " 'sleep': 22,\n",
       " 'meantime': 6,\n",
       " 'beer-runner': 1,\n",
       " 'solution': 45,\n",
       " 'Torrio': 7,\n",
       " \"O'Banion\": 15,\n",
       " 'message': 49,\n",
       " 'Dionie': 1,\n",
       " 'Johnny': 22,\n",
       " 'cops': 14,\n",
       " 'ass': 4,\n",
       " 'obligation': 12,\n",
       " 'countries': 111,\n",
       " 'members': 230,\n",
       " 'community': 154,\n",
       " 'cold': 13,\n",
       " 'advantage': 53,\n",
       " 'firm': 41,\n",
       " 'lawyer': 34,\n",
       " 'Day': 51,\n",
       " 'day': 467,\n",
       " 'week': 195,\n",
       " 'month': 96,\n",
       " 'betrayal': 5,\n",
       " \"Andrei's\": 2,\n",
       " 'heart': 131,\n",
       " 'A': 89,\n",
       " 'B': 76,\n",
       " 'need': 120,\n",
       " 'investment': 31,\n",
       " 'programs': 105,\n",
       " 'eyes': 289,\n",
       " 'Marty': 10,\n",
       " 'evocations': 2,\n",
       " 'place': 356,\n",
       " 'encounter': 14,\n",
       " 'man': 844,\n",
       " 'today': 190,\n",
       " 'run-ups': 1,\n",
       " 'price': 77,\n",
       " 'market': 100,\n",
       " 'price-earnings': 3,\n",
       " 'yield': 12,\n",
       " 'bases': 13,\n",
       " 'Morton': 14,\n",
       " 'everyone': 58,\n",
       " 'anything': 203,\n",
       " 'run-up': 1,\n",
       " 'Dr.': 139,\n",
       " 'Karlis': 1,\n",
       " 'Osis': 1,\n",
       " 'Director': 21,\n",
       " 'Research': 26,\n",
       " 'Parapsychology': 1,\n",
       " 'Foundation': 15,\n",
       " 'basis': 129,\n",
       " 'experiment': 44,\n",
       " 'tomorrow': 43,\n",
       " 'article': 36,\n",
       " 'Survival': 2,\n",
       " 'Death': 10,\n",
       " 'Spring': 17,\n",
       " 'rattle': 3,\n",
       " 'gunfire': 6,\n",
       " 'sides': 77,\n",
       " 'discussion': 68,\n",
       " 'policy': 154,\n",
       " 'outcome': 18,\n",
       " 'stage': 127,\n",
       " 'matter': 215,\n",
       " 'beginning': 58,\n",
       " 'school': 287,\n",
       " 'students': 157,\n",
       " 'cereal': 8,\n",
       " 'picnic': 10,\n",
       " 'bag': 33,\n",
       " 'grill': 8,\n",
       " 'cooler': 4,\n",
       " 'drinks': 15,\n",
       " 'beer': 26,\n",
       " 'foods': 29,\n",
       " 'Sunday': 73,\n",
       " 'evening': 96,\n",
       " 'program': 268,\n",
       " 'lectures': 11,\n",
       " 'music': 148,\n",
       " 'drama': 31,\n",
       " 'films': 22,\n",
       " 'issues': 45,\n",
       " 'tradition': 75,\n",
       " \"Williams's\": 2,\n",
       " 'support': 93,\n",
       " 'President-elect': 1,\n",
       " 'Kennedy': 113,\n",
       " 'Rules': 6,\n",
       " 'Committee': 61,\n",
       " 'bottleneck': 2,\n",
       " 'scope': 23,\n",
       " 'detail': 53,\n",
       " 'districts': 27,\n",
       " 'Rhode': 71,\n",
       " 'Island': 97,\n",
       " 'silver': 18,\n",
       " 'chloride': 4,\n",
       " 'Af': 722,\n",
       " 'Oak': 7,\n",
       " 'Ridge': 5,\n",
       " 'Laboratory': 11,\n",
       " 'Church': 98,\n",
       " 'pace': 28,\n",
       " 'purpose': 101,\n",
       " 'conference': 50,\n",
       " 'low-wage': 3,\n",
       " 'textile': 18,\n",
       " 'exports': 6,\n",
       " 'dumping': 2,\n",
       " 'products': 70,\n",
       " 'high-wage': 1,\n",
       " 'wealth': 15,\n",
       " 'experience': 186,\n",
       " 'Organization': 16,\n",
       " 'Cooperation': 3,\n",
       " 'studies': 66,\n",
       " 'face': 252,\n",
       " 'techniques': 78,\n",
       " 'police': 97,\n",
       " 'routine': 16,\n",
       " 'cooperation': 29,\n",
       " 'Energy': 3,\n",
       " 'Commission': 49,\n",
       " 'Department': 126,\n",
       " 'Education': 23,\n",
       " 'Welfare': 5,\n",
       " 'State': 199,\n",
       " 'interest': 243,\n",
       " 'objectives': 31,\n",
       " 'Act': 85,\n",
       " 'East': 38,\n",
       " 'government': 210,\n",
       " 'waitresses': 1,\n",
       " 'English': 63,\n",
       " 'counter': 17,\n",
       " 'Yuki': 1,\n",
       " 'Kobayashi': 1,\n",
       " 'kind': 215,\n",
       " 'homesteads': 1,\n",
       " 'pioneers': 1,\n",
       " 'frontier': 21,\n",
       " 'Swadesh': 7,\n",
       " 'list': 91,\n",
       " 'knowledge': 104,\n",
       " 'diagnosis': 9,\n",
       " 'treatment': 99,\n",
       " 'miles': 128,\n",
       " 'north': 46,\n",
       " 'Mount': 12,\n",
       " 'Moosilauke': 1,\n",
       " \"Dartmouth's\": 3,\n",
       " 'mountain': 19,\n",
       " 'Artie': 7,\n",
       " 'snorkle': 2,\n",
       " 'forefinger': 5,\n",
       " 'nucleus': 10,\n",
       " 'charge': 78,\n",
       " 'electricity': 19,\n",
       " 'electrons': 6,\n",
       " 'orbits': 9,\n",
       " 'motorist': 1,\n",
       " 'Richard': 55,\n",
       " 'Sarkees': 2,\n",
       " 'McClellan': 11,\n",
       " 'probation': 4,\n",
       " 'court': 84,\n",
       " 'order': 251,\n",
       " 'necks': 2,\n",
       " 'wonders': 6,\n",
       " 'space': 138,\n",
       " 'imagination': 53,\n",
       " 'public': 103,\n",
       " 'Carla': 11,\n",
       " 'Caneli': 1,\n",
       " 'stockade': 9,\n",
       " 'rifles': 18,\n",
       " 'guerrillas': 11,\n",
       " 'shadows': 15,\n",
       " 'Apaches': 4,\n",
       " 'deadlock': 7,\n",
       " \"Russians'\": 1,\n",
       " 'demand': 59,\n",
       " 'directorate': 4,\n",
       " 'veto': 7,\n",
       " 'control': 134,\n",
       " 'machinery': 45,\n",
       " 'Hetty': 2,\n",
       " 'contrast': 53,\n",
       " 'amount': 108,\n",
       " 'information': 192,\n",
       " 'bride': 23,\n",
       " 'groom': 4,\n",
       " 'Gore': 6,\n",
       " 'Court': 83,\n",
       " 'glories': 3,\n",
       " 'Tudor': 4,\n",
       " 'splendor': 4,\n",
       " 'proposals': 19,\n",
       " 'atmosphere': 65,\n",
       " 'individual': 60,\n",
       " 'turn': 63,\n",
       " 'technology': 26,\n",
       " 'Nikita': 7,\n",
       " \"Khrushchev's\": 11,\n",
       " 'eulogizers': 1,\n",
       " \"U.S.S.R.'s\": 1,\n",
       " 'Izvestia': 1,\n",
       " 'Comedian': 1,\n",
       " 'Charlie': 39,\n",
       " 'Chaplin': 3,\n",
       " 'villa': 2,\n",
       " 'self-exile': 1,\n",
       " 'suit': 24,\n",
       " 'presences': 1,\n",
       " 'metabolism': 1,\n",
       " 'Pasadena': 4,\n",
       " 'listings': 1,\n",
       " 'moves': 8,\n",
       " 'businessmen': 11,\n",
       " 'lines': 138,\n",
       " 'slowness': 3,\n",
       " 'elevator': 11,\n",
       " 'adjustments': 16,\n",
       " 'fruit': 24,\n",
       " 'Joyce': 18,\n",
       " 'situation': 155,\n",
       " 'gun': 66,\n",
       " 'Negroes': 45,\n",
       " 'Boston': 49,\n",
       " 'course': 356,\n",
       " 'slaves': 31,\n",
       " 'bubbles': 10,\n",
       " 'night': 299,\n",
       " 'being': 20,\n",
       " 'alarm': 14,\n",
       " 'web': 3,\n",
       " 'planners': 10,\n",
       " 'Taiwan': 5,\n",
       " 'men': 549,\n",
       " 'U.S.': 114,\n",
       " 'Senate': 44,\n",
       " 'hog': 2,\n",
       " 'Jackson': 28,\n",
       " 'Rusk': 8,\n",
       " 'department': 42,\n",
       " 'personnel': 57,\n",
       " 'Sen.': 23,\n",
       " 'work': 441,\n",
       " 'comment': 29,\n",
       " \"Eisenhower's\": 6,\n",
       " 'Goals': 2,\n",
       " 'Americans': 70,\n",
       " 'gainers': 1,\n",
       " 'poetry': 56,\n",
       " 'delight': 19,\n",
       " 'profanity': 4,\n",
       " 'parents': 64,\n",
       " 'Charles': 73,\n",
       " 'Blatz': 6,\n",
       " 'cellar': 22,\n",
       " 'stairs': 42,\n",
       " 'Belgians': 17,\n",
       " 'development': 233,\n",
       " 'Congo': 43,\n",
       " 'copper': 9,\n",
       " 'tin': 9,\n",
       " 'cobalt': 2,\n",
       " 'manganese': 1,\n",
       " 'zinc': 7,\n",
       " 'uranium': 3,\n",
       " 'cotton': 21,\n",
       " 'palm': 13,\n",
       " 'oil': 69,\n",
       " 'metabolites': 1,\n",
       " 'p-aminobenzoic': 1,\n",
       " 'acid': 8,\n",
       " 'PABA': 2,\n",
       " 'cofactors': 1,\n",
       " 'hydroxylation': 1,\n",
       " 'aniline': 1,\n",
       " 'bacteria': 6,\n",
       " 'Aj': 85,\n",
       " 'Ice': 2,\n",
       " 'aerator': 7,\n",
       " 'drive': 31,\n",
       " 'belts': 3,\n",
       " 'silence': 36,\n",
       " 'Bertha': 3,\n",
       " 'Madeira': 1,\n",
       " \"Today's\": 6,\n",
       " 'Voice': 4,\n",
       " \"Fromm's\": 13,\n",
       " 'analysis': 82,\n",
       " 'alienation': 20,\n",
       " 'sphere': 17,\n",
       " 'production': 107,\n",
       " 'concepts': 24,\n",
       " 'bureaucratization': 1,\n",
       " 'corporation': 46,\n",
       " 'separation': 12,\n",
       " 'ownership': 15,\n",
       " 'view': 122,\n",
       " 'dispersion': 3,\n",
       " 'World': 83,\n",
       " 'War': 126,\n",
       " 'Baker': 25,\n",
       " 'Draft': 7,\n",
       " 'sale': 34,\n",
       " 'liquor': 27,\n",
       " 'uniform': 18,\n",
       " 'zones': 2,\n",
       " 'camps': 16,\n",
       " 'prostitution': 7,\n",
       " 'reasons': 74,\n",
       " 'interview': 22,\n",
       " 'fact': 353,\n",
       " 'ways': 93,\n",
       " 'progress': 86,\n",
       " 'therapy': 8,\n",
       " 'bill': 61,\n",
       " 'Assembly': 20,\n",
       " 'May': 67,\n",
       " 'scrutiny': 12,\n",
       " 'partner': 25,\n",
       " 'connective': 1,\n",
       " 'system': 300,\n",
       " 'network': 25,\n",
       " 'requirements': 56,\n",
       " 'objective': 44,\n",
       " 'body': 184,\n",
       " 'unit': 75,\n",
       " 'communication': 45,\n",
       " 'factory': 16,\n",
       " 'college': 119,\n",
       " 'village': 30,\n",
       " 'Skyros': 14,\n",
       " 'Angie': 15,\n",
       " 'Prettyman': 2,\n",
       " 'boys': 97,\n",
       " 'salesman': 8,\n",
       " 'nuisance': 4,\n",
       " 'danger': 49,\n",
       " 'touch': 41,\n",
       " 'bunch': 16,\n",
       " 'everything': 116,\n",
       " 'sort': 126,\n",
       " 'contact': 39,\n",
       " 'hall': 81,\n",
       " 'land': 145,\n",
       " 'Prokofieff': 24,\n",
       " 'conditions': 142,\n",
       " 'incentive': 8,\n",
       " 'security': 54,\n",
       " 'opportunities': 35,\n",
       " 'idioms': 3,\n",
       " 'fermentations': 1,\n",
       " 'ideology': 10,\n",
       " 'performers': 12,\n",
       " 'prepolymer': 4,\n",
       " 'isocyanate': 2,\n",
       " 'resin': 9,\n",
       " 'foaming': 4,\n",
       " 'militia': 9,\n",
       " 'west': 36,\n",
       " 'clusters': 5,\n",
       " 'road': 139,\n",
       " 'Hal': 22,\n",
       " 'side': 283,\n",
       " 'Earth': 26,\n",
       " 'zone': 7,\n",
       " 'Sigmen': 4,\n",
       " 'City': 102,\n",
       " 'voice': 163,\n",
       " 'mess': 15,\n",
       " 'sense': 223,\n",
       " 'editors': 13,\n",
       " 'story': 112,\n",
       " 'value': 159,\n",
       " 'example': 214,\n",
       " 'reduction': 32,\n",
       " 'nature': 146,\n",
       " 'disease': 42,\n",
       " 'life': 508,\n",
       " 'subterfuges': 1,\n",
       " 'lies': 3,\n",
       " 'frauds': 3,\n",
       " 'errors': 34,\n",
       " 'sins': 8,\n",
       " 'crimes': 11,\n",
       " 'efforts': 93,\n",
       " 'advantages': 20,\n",
       " 'race': 77,\n",
       " 'businesses': 14,\n",
       " 'profit': 22,\n",
       " 'votes': 12,\n",
       " 'girl': 163,\n",
       " 'investigators': 9,\n",
       " 'salt-fractionation': 1,\n",
       " 'fractionation': 2,\n",
       " 'solvents': 3,\n",
       " 'acetone': 3,\n",
       " 'addition': 101,\n",
       " 'incompleteness': 1,\n",
       " 'science': 74,\n",
       " 'completeness': 3,\n",
       " 'metaphysics': 9,\n",
       " 'philosophy': 63,\n",
       " 'forms': 84,\n",
       " 'Nothing': 44,\n",
       " 'nothing': 263,\n",
       " 'Wright': 39,\n",
       " 'morning': 161,\n",
       " 'Tokyo': 12,\n",
       " 'Holland': 6,\n",
       " 'company': 165,\n",
       " 'mint': 7,\n",
       " 'nudge': 1,\n",
       " 'radio': 75,\n",
       " 'emission': 23,\n",
       " 'planet': 19,\n",
       " 'Burke': 7,\n",
       " 'Franklin': 20,\n",
       " 'origin': 29,\n",
       " 'noise': 31,\n",
       " 'records': 64,\n",
       " 'meters': 11,\n",
       " 'wave': 42,\n",
       " 'length': 91,\n",
       " 'Jupiter': 6,\n",
       " 'boy': 181,\n",
       " 'Air': 28,\n",
       " 'Force': 19,\n",
       " 'fullback': 2,\n",
       " 'Nick': 17,\n",
       " 'Arshinkoff': 1,\n",
       " 'football': 23,\n",
       " 'seconds': 16,\n",
       " 'barn': 24,\n",
       " 'splinters': 1,\n",
       " 'outlaw': 2,\n",
       " 'transit': 13,\n",
       " 'mirror': 24,\n",
       " 'accelerometers': 7,\n",
       " 'platform': 51,\n",
       " 'Peace': 48,\n",
       " 'Corps': 60,\n",
       " 'volunteers': 17,\n",
       " 'tax': 139,\n",
       " 'benefit': 38,\n",
       " 'law': 202,\n",
       " 'agency': 36,\n",
       " 'answer': 86,\n",
       " 'garage': 16,\n",
       " 'couple': 87,\n",
       " 'days': 273,\n",
       " 'M.': 47,\n",
       " \"Forbes's\": 1,\n",
       " 'Paget': 1,\n",
       " 'lead': 40,\n",
       " 'stages': 37,\n",
       " 'wire': 30,\n",
       " 'head': 295,\n",
       " 'Glen': 4,\n",
       " 'T.': 20,\n",
       " \"Hallowell's\": 1,\n",
       " 'Milties': 1,\n",
       " 'Miss': 177,\n",
       " 'appearance': 47,\n",
       " 'Rumanians': 1,\n",
       " 'showcase': 3,\n",
       " 'archaism': 1,\n",
       " 'Stravinsky': 7,\n",
       " 'bleeps': 1,\n",
       " 'bloops': 1,\n",
       " 'anniversary': 12,\n",
       " \"Russell's\": 4,\n",
       " 'run': 41,\n",
       " 'Skylark': 1,\n",
       " 'Drury': 2,\n",
       " 'Lane': 15,\n",
       " 'sellout': 1,\n",
       " 'Linda': 31,\n",
       " 'Kay': 16,\n",
       " 'bedroom': 40,\n",
       " 'Submarines': 1,\n",
       " 'shore': 35,\n",
       " 'installations': 10,\n",
       " 'elements': 68,\n",
       " 'Katanga': 19,\n",
       " 'territory': 24,\n",
       " 'chaos': 15,\n",
       " 'eye': 93,\n",
       " 'Moll': 4,\n",
       " 'officer': 53,\n",
       " 'comfort': 29,\n",
       " 'words': 197,\n",
       " 'darkness': 34,\n",
       " 'corner': 80,\n",
       " 'structures': 22,\n",
       " 'apartments': 9,\n",
       " 'masonry': 4,\n",
       " 'frame': 49,\n",
       " 'construction': 65,\n",
       " 'rocks': 20,\n",
       " 'water': 337,\n",
       " 'sea': 63,\n",
       " 'everybody': 45,\n",
       " 'grudge': 5,\n",
       " 'inception': 4,\n",
       " 'change': 110,\n",
       " 'factors': 78,\n",
       " 'Police': 17,\n",
       " 'barber': 2,\n",
       " 'shop': 36,\n",
       " 'Pratt': 8,\n",
       " 'Street': 64,\n",
       " 'lulls': 1,\n",
       " 'one-fourth': 6,\n",
       " 'acres': 36,\n",
       " 'debris': 7,\n",
       " 'concentration': 34,\n",
       " 'snags': 1,\n",
       " 'lightning-occurrence': 1,\n",
       " 'areas': 180,\n",
       " 'roadside': 4,\n",
       " 'fuel': 16,\n",
       " 'firebreaks': 1,\n",
       " 'plaque': 1,\n",
       " 'Others': 25,\n",
       " 'trade': 87,\n",
       " 'operand': 12,\n",
       " 'column': 40,\n",
       " 'sheet': 35,\n",
       " 'Strings': 3,\n",
       " 'souls': 17,\n",
       " 'goal': 43,\n",
       " 'guy': 34,\n",
       " 'blow': 18,\n",
       " 'borderline': 2,\n",
       " 'Corso': 6,\n",
       " 'Vittorio': 2,\n",
       " 'Emanuele': 2,\n",
       " 'Del': 8,\n",
       " 'Rinascimento': 2,\n",
       " 'yards': 52,\n",
       " 'left': 52,\n",
       " 'Via': 24,\n",
       " 'Dei': 3,\n",
       " 'Canestrani': 1,\n",
       " 'Piazza': 6,\n",
       " 'Navona': 4,\n",
       " 'sights': 12,\n",
       " 'Rome': 50,\n",
       " 'notation': 2,\n",
       " 'proof': 20,\n",
       " 'Theorem': 7,\n",
       " 'look': 75,\n",
       " 'case': 260,\n",
       " 'polynomial': 22,\n",
       " 'T': 58,\n",
       " 'product': 67,\n",
       " 'first-degree': 1,\n",
       " 'polynomials': 9,\n",
       " 'heaven': 17,\n",
       " 'nothin': 2,\n",
       " 'nigger': 10,\n",
       " 'pussy': 4,\n",
       " 'Brewers': 1,\n",
       " 'corn': 22,\n",
       " 'rice': 19,\n",
       " 'barley': 5,\n",
       " 'conversion': 13,\n",
       " 'manure': 6,\n",
       " 'Mays': 9,\n",
       " 'Mantle': 37,\n",
       " 'ability': 53,\n",
       " 'baseball': 31,\n",
       " 'heights': 12,\n",
       " 'result': 148,\n",
       " 'Board': 54,\n",
       " 'plan': 127,\n",
       " 'Negro': 86,\n",
       " 'schools': 133,\n",
       " 'linguist': 13,\n",
       " 'complement': 15,\n",
       " 'corporations': 18,\n",
       " 'figure': 115,\n",
       " 'birth': 53,\n",
       " 'female': 23,\n",
       " 'chapter': 31,\n",
       " 'Laying': 1,\n",
       " 'Birth': 3,\n",
       " 'headline': 4,\n",
       " 'pair': 36,\n",
       " 'lot': 94,\n",
       " 'tossing': 1,\n",
       " 'coins': 8,\n",
       " 'safeguard': 3,\n",
       " 'reference': 48,\n",
       " 'oracles': 1,\n",
       " 'I': 2,\n",
       " 'Ching': 4,\n",
       " 'Book': 12,\n",
       " 'Changes': 4,\n",
       " 'handling': 18,\n",
       " 'materials': 72,\n",
       " 'spout': 1,\n",
       " 'designs': 17,\n",
       " 'area': 247,\n",
       " 'clay': 63,\n",
       " 'fun': 35,\n",
       " 'sausages': 3,\n",
       " 'charcoal': 11,\n",
       " 'burners': 2,\n",
       " 'sauces': 4,\n",
       " 'group': 285,\n",
       " 'Adam': 30,\n",
       " 'defense': 87,\n",
       " 'secret': 20,\n",
       " 'part': 332,\n",
       " 'end': 276,\n",
       " 'nestling': 1,\n",
       " 'languages': 28,\n",
       " 'child': 159,\n",
       " 'kick-up': 1,\n",
       " 'teacher': 55,\n",
       " 'help': 68,\n",
       " 'years': 677,\n",
       " 'authorization': 2,\n",
       " 'sums': 13,\n",
       " 'provisions': 27,\n",
       " 'Fort': 34,\n",
       " 'Lauderdale': 4,\n",
       " 'Robinson': 26,\n",
       " 'Herford': 5,\n",
       " \"club's\": 6,\n",
       " 'lavatory': 1,\n",
       " 'highball': 3,\n",
       " 'game': 93,\n",
       " 'cards': 26,\n",
       " 'sight': 65,\n",
       " \"man's\": 80,\n",
       " 'prep': 2,\n",
       " 'university': 66,\n",
       " 'whole': 35,\n",
       " 'Berlin': 61,\n",
       " 'status': 73,\n",
       " 'image': 93,\n",
       " 'prisoner': 6,\n",
       " 'irons': 7,\n",
       " 'award': 27,\n",
       " 'honor': 38,\n",
       " 'history': 203,\n",
       " 'JA': 1,\n",
       " 'activities': 83,\n",
       " 'Portland': 21,\n",
       " 'Ralph': 20,\n",
       " 'Scolatti': 1,\n",
       " 'executive': 21,\n",
       " 'director': 61,\n",
       " 'Achievement': 7,\n",
       " 'material': 121,\n",
       " 'sampling': 8,\n",
       " 'assessment': 16,\n",
       " 'Plummer': 2,\n",
       " 'remark': 17,\n",
       " 'Green': 9,\n",
       " 'landing': 9,\n",
       " 'Saxons': 7,\n",
       " 'step': 83,\n",
       " 'woman': 159,\n",
       " 'embassies': 5,\n",
       " \"Arabs'\": 1,\n",
       " 'Arabs': 1,\n",
       " 'Saudi': 1,\n",
       " 'Arabians': 1,\n",
       " 'Varlaam': 3,\n",
       " 'Missail': 1,\n",
       " 'idiom': 6,\n",
       " 'Pimen': 4,\n",
       " 'service': 187,\n",
       " 'Alfredo': 1,\n",
       " 'Antonini': 1,\n",
       " 'diet': 13,\n",
       " 'performances': 28,\n",
       " 'Stadium': 13,\n",
       " 'Symphony': 21,\n",
       " 'America': 149,\n",
       " 'recruitment': 4,\n",
       " 'pattern': 82,\n",
       " 'integration': 36,\n",
       " 'congregation': 30,\n",
       " 'Birgit': 1,\n",
       " 'Nilsson': 1,\n",
       " 'newspaperman': 3,\n",
       " 'cable': 3,\n",
       " 'office': 158,\n",
       " 'station': 76,\n",
       " 'cowbirds': 3,\n",
       " 'ground': 135,\n",
       " 'cardinal': 1,\n",
       " 'vestments': 1,\n",
       " 'roads': 38,\n",
       " 'floor': 117,\n",
       " 'access': 21,\n",
       " 'serum': 11,\n",
       " 'type': 144,\n",
       " 'antibodies': 8,\n",
       " 'activity': 93,\n",
       " 'regions': 31,\n",
       " 'Fig.': 44,\n",
       " 'meteorites': 7,\n",
       " 'nickel': 5,\n",
       " 'content': 29,\n",
       " 'cent': 127,\n",
       " 'Rock': 17,\n",
       " 'observations': 27,\n",
       " 'house': 301,\n",
       " 'plumbing': 6,\n",
       " 'cost': 137,\n",
       " 'improvements': 14,\n",
       " 'lady': 38,\n",
       " 'collar': 11,\n",
       " 'bosom': 6,\n",
       " 'functions': 33,\n",
       " 'Section': 47,\n",
       " 'Secretary': 110,\n",
       " 'grandson': 2,\n",
       " 'chieftain': 3,\n",
       " 'Taui': 1,\n",
       " 'magic': 13,\n",
       " 'ratio': 26,\n",
       " 'automobiles': 21,\n",
       " 'state': 399,\n",
       " 'E': 27,\n",
       " 'execution': 9,\n",
       " 'moment': 184,\n",
       " 'strike': 21,\n",
       " 'accumulation': 9,\n",
       " 'vines': 8,\n",
       " 'weeds': 5,\n",
       " 'moldboard': 1,\n",
       " 'dust': 51,\n",
       " 'plow': 8,\n",
       " 'team': 58,\n",
       " 'rein': 3,\n",
       " 'line': 209,\n",
       " 'L': 10,\n",
       " 'Q': 34,\n",
       " 'points': 90,\n",
       " 'generator': 12,\n",
       " 'regulus': 6,\n",
       " 'secants': 13,\n",
       " 'Age': 4,\n",
       " 'rating': 4,\n",
       " 'age': 161,\n",
       " 'Elbow': 3,\n",
       " 'Shoulder': 2,\n",
       " 'Knee': 2,\n",
       " 'Foot': 2,\n",
       " 'Hand': 9,\n",
       " 'method': 110,\n",
       " 'choice': 78,\n",
       " 'aspects': 51,\n",
       " 'childhood': 39,\n",
       " 'Mike': 69,\n",
       " 'Deegan': 18,\n",
       " 'rubber': 8,\n",
       " 'plate': 13,\n",
       " 'bat': 8,\n",
       " 'Party': 18,\n",
       " 'Friends': 9,\n",
       " \"America's\": 17,\n",
       " 'position': 172,\n",
       " 'luck': 36,\n",
       " \"town's\": 9,\n",
       " 'limits': 29,\n",
       " 'experiments': 45,\n",
       " 'Romagnosi': 1,\n",
       " 'others': 225,\n",
       " 'relationship': 63,\n",
       " 'forces': 100,\n",
       " \"Alec's\": 4,\n",
       " 'typewriter': 8,\n",
       " '$2,000': 3,\n",
       " ...}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emission_counts[\"NOUN\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPLEMENTATION: Most Frequent Class Tagger\n",
    "\n",
    "Use the `pair_counts()` function and the training dataset to find the most frequent class label for each word in the training data, and populate the `mfc_table` below. The table keys should be words, and the values should be the appropriate tag string.\n",
    "\n",
    "The `MFCTagger` class is provided to mock the interface of Pomegranite HMM models so that they can be used interchangeably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lookup table mfc_table where mfc_table[word] contains the tag label most frequently assigned to that word\n",
    "\n",
    "from collections import namedtuple\n",
    "import operator\n",
    "\n",
    "FakeState = namedtuple(\"FakeState\", \"name\")\n",
    "\n",
    "class MFCTagger:\n",
    "    \n",
    "    missing = FakeState(name=\"<MISSING>\")\n",
    "    \n",
    "    def __init__(self, table):\n",
    "        self.table = defaultdict(lambda: MFCTagger.missing)\n",
    "        self.table.update({word: FakeState(name=tag) for word, tag in table.items()})\n",
    "        \n",
    "    def viterbi(self, seq):\n",
    "        \"\"\"This method simplifies predictions by matching the Pomegranate viterbi() interface\"\"\"\n",
    "        return 0., list(enumerate([\"<start>\"] + [self.table[w] for w in seq] + [\"<end>\"]))\n",
    "\n",
    "word_counts = pair_counts(data.training_set.X, data.training_set.Y)\n",
    "\n",
    "mfc_table = {}\n",
    "\n",
    "for word in data.training_set.vocab:\n",
    "    tag_val = max(word_counts[word].keys(), key=(lambda k: word_counts[word][k]))        \n",
    "    mfc_table[word] = tag_val\n",
    "\n",
    "mfc_model = MFCTagger(mfc_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spraying': 'VERB',\n",
       " 'shimmering': 'VERB',\n",
       " 'Arrangement': 'NOUN',\n",
       " 'event': 'NOUN',\n",
       " 'Spectacular': 'ADJ',\n",
       " 'dined': 'VERB',\n",
       " 'under-developed': 'ADJ',\n",
       " 'roadbed': 'NOUN',\n",
       " 'relationships': 'NOUN',\n",
       " 'dusty': 'ADJ',\n",
       " 'yellowish': 'ADJ',\n",
       " 'thoroughfare': 'NOUN',\n",
       " 'Status-roles': 'NOUN',\n",
       " 'oblong': 'ADJ',\n",
       " 'Westerners': 'NOUN',\n",
       " 'Australian': 'NOUN',\n",
       " 'Greville': 'NOUN',\n",
       " 'Wansee': 'NOUN',\n",
       " 'canker': 'NOUN',\n",
       " 'Curiously': 'ADV',\n",
       " 'Weidman': 'NOUN',\n",
       " 'generalities': 'NOUN',\n",
       " \"Susan's\": 'NOUN',\n",
       " '357': 'NUM',\n",
       " 'Rag': 'NOUN',\n",
       " 'Tunisia': 'NOUN',\n",
       " 'roaring': 'VERB',\n",
       " 'Samples': 'NOUN',\n",
       " 'self': 'NOUN',\n",
       " 'rudely': 'ADV',\n",
       " 'hard-to-please': 'ADJ',\n",
       " 'farmlands': 'NOUN',\n",
       " 'crowd': 'NOUN',\n",
       " 'part': 'NOUN',\n",
       " 'posse': 'NOUN',\n",
       " 'Katie': 'NOUN',\n",
       " 'clamps': 'NOUN',\n",
       " 'Hanover-Pebble': 'NOUN',\n",
       " 'buoyancy': 'NOUN',\n",
       " \"Colt's\": 'NOUN',\n",
       " 'god-like': 'ADJ',\n",
       " 'discharged': 'VERB',\n",
       " 'occurs': 'VERB',\n",
       " 'launched': 'VERB',\n",
       " 'unload': 'VERB',\n",
       " 'synthetics': 'NOUN',\n",
       " 'Eligio': 'NOUN',\n",
       " 'duffers': 'NOUN',\n",
       " 'Zanzibar': 'NOUN',\n",
       " 'stage': 'NOUN',\n",
       " 'Compute': 'VERB',\n",
       " 'minutiae': 'NOUN',\n",
       " 'Miguel': 'NOUN',\n",
       " 'stinkpotters': 'NOUN',\n",
       " 'Burma': 'NOUN',\n",
       " 'Relativism': 'NOUN',\n",
       " '1957b': 'NUM',\n",
       " 'where': 'ADV',\n",
       " 'pans': 'NOUN',\n",
       " 'Swartz': 'NOUN',\n",
       " 'Cumberland': 'NOUN',\n",
       " \"kid's\": 'NOUN',\n",
       " 'chinked': 'VERB',\n",
       " 'circonscription': 'X',\n",
       " 'mph': 'NOUN',\n",
       " 'Duke': 'NOUN',\n",
       " 'Creek-Turn': 'NOUN',\n",
       " 'Arteries': 'NOUN',\n",
       " 'served': 'VERB',\n",
       " 'Mater': 'X',\n",
       " 'foot': 'NOUN',\n",
       " 'Whitehead': 'NOUN',\n",
       " 'Happy': 'ADJ',\n",
       " 'exalted': 'VERB',\n",
       " 'vagueness': 'NOUN',\n",
       " 'Moses': 'NOUN',\n",
       " 'Minoan-Mycenaean': 'ADJ',\n",
       " \"Kroger's\": 'NOUN',\n",
       " 'long-established': 'ADJ',\n",
       " 'rollickingly': 'ADV',\n",
       " 'carbonyl': 'NOUN',\n",
       " 'beryllium': 'NOUN',\n",
       " 'continuities': 'NOUN',\n",
       " 'pool-equipment': 'NOUN',\n",
       " 'blue-uniformed': 'ADJ',\n",
       " 'historians': 'NOUN',\n",
       " 'justify': 'VERB',\n",
       " 'datum': 'NOUN',\n",
       " 'Bohemian': 'NOUN',\n",
       " 'clergyman': 'NOUN',\n",
       " 'conformational': 'NOUN',\n",
       " 'suburbanized': 'VERB',\n",
       " 'Springs': 'NOUN',\n",
       " 'Puttana': 'X',\n",
       " 'sits': 'VERB',\n",
       " 'seen': 'VERB',\n",
       " 'Timmy': 'NOUN',\n",
       " 'sprinkling': 'NOUN',\n",
       " 'controls': 'NOUN',\n",
       " 'neuropathology': 'NOUN',\n",
       " 'leg': 'NOUN',\n",
       " 'unison': 'NOUN',\n",
       " 'misconstructions': 'NOUN',\n",
       " 'studies': 'NOUN',\n",
       " 'desert': 'NOUN',\n",
       " 'hilum': 'NOUN',\n",
       " 'sonofabitch': 'NOUN',\n",
       " 'fellows': 'NOUN',\n",
       " 'superstitious': 'ADJ',\n",
       " 'multi-purpose': 'ADJ',\n",
       " 'philosophized': 'VERB',\n",
       " 'cross-examination': 'NOUN',\n",
       " 'worries': 'NOUN',\n",
       " 'sluice': 'NOUN',\n",
       " \"manager's\": 'NOUN',\n",
       " 'Finland': 'NOUN',\n",
       " '-.5': 'NUM',\n",
       " 'sobered': 'VERB',\n",
       " 'clarifying': 'VERB',\n",
       " 'underway': 'ADV',\n",
       " 'Greek-speaking': 'ADJ',\n",
       " 'Foy': 'NOUN',\n",
       " 'valor': 'NOUN',\n",
       " 'Association': 'NOUN',\n",
       " 'stewed': 'VERB',\n",
       " 'battlefield': 'NOUN',\n",
       " 'preying': 'VERB',\n",
       " 'stitched': 'VERB',\n",
       " \"conductor's\": 'NOUN',\n",
       " 'stunk': 'VERB',\n",
       " 'broccoli': 'NOUN',\n",
       " 'Pressure': 'NOUN',\n",
       " 'scars': 'NOUN',\n",
       " 'covered': 'VERB',\n",
       " 'sluggish': 'ADJ',\n",
       " 'inapt': 'ADJ',\n",
       " 'Results': 'NOUN',\n",
       " 'stormbound': 'ADJ',\n",
       " 'Impatiently': 'ADV',\n",
       " '1900': 'NUM',\n",
       " 'Direction': 'NOUN',\n",
       " 'groggy': 'ADJ',\n",
       " '8,280': 'NUM',\n",
       " 'ridiculous': 'ADJ',\n",
       " 'distiller': 'NOUN',\n",
       " 'Inner': 'ADJ',\n",
       " 'Gardner': 'NOUN',\n",
       " \"comet's-tail\": 'NOUN',\n",
       " \"Montgomery's\": 'NOUN',\n",
       " 'cancer': 'NOUN',\n",
       " 'citation': 'NOUN',\n",
       " 'robber': 'NOUN',\n",
       " 'Flushing': 'NOUN',\n",
       " 'plenitude': 'NOUN',\n",
       " 'strictures': 'NOUN',\n",
       " 'influenza-pneumonia': 'NOUN',\n",
       " 'warden': 'NOUN',\n",
       " 'jesting': 'VERB',\n",
       " 'equipping': 'NOUN',\n",
       " 'dissension': 'NOUN',\n",
       " 'chancel': 'NOUN',\n",
       " 'revered': 'VERB',\n",
       " 'companionway': 'NOUN',\n",
       " 'instigator': 'NOUN',\n",
       " 'Auxiliary': 'NOUN',\n",
       " \"Talbott's\": 'NOUN',\n",
       " 'ESN': 'NOUN',\n",
       " 'Required': 'VERB',\n",
       " 'compactly': 'ADV',\n",
       " 'piquant': 'ADJ',\n",
       " 'sundown': 'NOUN',\n",
       " 'qualified': 'VERB',\n",
       " 'visits': 'NOUN',\n",
       " 'john': 'NOUN',\n",
       " 'Op.': 'NOUN',\n",
       " 'Handsome': 'ADJ',\n",
       " 'overpowers': 'VERB',\n",
       " 'Elaborate': 'ADJ',\n",
       " 'Corporation': 'NOUN',\n",
       " 'Hyde': 'NOUN',\n",
       " '1896': 'NUM',\n",
       " 'Calm': 'ADJ',\n",
       " 'Erde': 'X',\n",
       " 'nab': 'VERB',\n",
       " \"Palfrey's\": 'NOUN',\n",
       " 'soak': 'VERB',\n",
       " '45%': 'NOUN',\n",
       " 'rose-pink': 'ADJ',\n",
       " 'native': 'ADJ',\n",
       " 'sprinkled': 'VERB',\n",
       " 'seemed': 'VERB',\n",
       " 'Norfolk': 'NOUN',\n",
       " 'Sears': 'NOUN',\n",
       " 'Sundays': 'NOUN',\n",
       " 'arteriolar-pulmonary': 'ADJ',\n",
       " 'Yuba': 'NOUN',\n",
       " 'Rumford': 'NOUN',\n",
       " 'portents': 'NOUN',\n",
       " 'Bales': 'NOUN',\n",
       " 'Castro': 'NOUN',\n",
       " 'brindle': 'NOUN',\n",
       " 'queerer': 'ADJ',\n",
       " 'mosaic': 'NOUN',\n",
       " 'lug': 'VERB',\n",
       " '1-1/2': 'NUM',\n",
       " 'negatively': 'ADV',\n",
       " 'Refund': 'NOUN',\n",
       " 'stiffened': 'VERB',\n",
       " 'Newest': 'ADJ',\n",
       " 'Neuberger': 'NOUN',\n",
       " 'tenant': 'NOUN',\n",
       " 'excruciating': 'ADJ',\n",
       " 'Scotch-and-soda': 'NOUN',\n",
       " 'dissolution': 'NOUN',\n",
       " 'redheaded': 'ADJ',\n",
       " 'legibility': 'NOUN',\n",
       " 'florid': 'ADJ',\n",
       " 'uncle': 'NOUN',\n",
       " 'Session': 'NOUN',\n",
       " 'licked': 'VERB',\n",
       " 'KC': 'NOUN',\n",
       " 'Rather': 'ADV',\n",
       " 'non-systematic': 'ADJ',\n",
       " 'Redoute': 'X',\n",
       " 'Middle-Eastern': 'ADJ',\n",
       " 'M-K': 'NOUN',\n",
       " 'Youths': 'NOUN',\n",
       " 'Leary': 'NOUN',\n",
       " 'Gimpy': 'NOUN',\n",
       " 'crown': 'NOUN',\n",
       " 'peerless': 'ADJ',\n",
       " 'frambesia': 'NOUN',\n",
       " 'glass-like': 'ADJ',\n",
       " 'Thirty-four': 'NUM',\n",
       " 'Picasso': 'NOUN',\n",
       " 'Manin': 'NOUN',\n",
       " 'Fourteenth': 'ADJ',\n",
       " 'capacity': 'NOUN',\n",
       " \"tailin'\": 'NOUN',\n",
       " 'corn-belt': 'NOUN',\n",
       " 'separators': 'NOUN',\n",
       " 'Balafrej': 'NOUN',\n",
       " 'forty': 'NUM',\n",
       " 'Energy': 'NOUN',\n",
       " 'week-old': 'ADJ',\n",
       " 'Leibowitz': 'NOUN',\n",
       " 'showy': 'ADJ',\n",
       " 'panoramas': 'NOUN',\n",
       " 'fern': 'NOUN',\n",
       " 'models': 'NOUN',\n",
       " 'Brandel': 'NOUN',\n",
       " 'apportioned': 'VERB',\n",
       " 'flog': 'VERB',\n",
       " 'aura': 'NOUN',\n",
       " 'Passage': 'NOUN',\n",
       " 'horned': 'ADJ',\n",
       " 'aforementioned': 'ADJ',\n",
       " \"footballer's\": 'NOUN',\n",
       " 'Dickson': 'NOUN',\n",
       " 'Mlle': 'NOUN',\n",
       " 'nerve-ends': 'NOUN',\n",
       " 'Lecky': 'NOUN',\n",
       " 'Well': 'PRT',\n",
       " 'McNeil': 'NOUN',\n",
       " 'spirit': 'NOUN',\n",
       " 'envision': 'VERB',\n",
       " 'Abilene': 'NOUN',\n",
       " 'churchmen': 'NOUN',\n",
       " 'summed': 'VERB',\n",
       " 'blebs': 'NOUN',\n",
       " 'long-familiar': 'ADJ',\n",
       " 'uselessly': 'ADV',\n",
       " 'Rockfork': 'NOUN',\n",
       " 'deluxer': 'NOUN',\n",
       " 'chowder': 'NOUN',\n",
       " 'storehouse': 'NOUN',\n",
       " 'soothe': 'VERB',\n",
       " 'Patients': 'NOUN',\n",
       " 'Colefax': 'NOUN',\n",
       " 'byline': 'NOUN',\n",
       " 'pounding': 'VERB',\n",
       " \"London's\": 'NOUN',\n",
       " 'Auntie': 'NOUN',\n",
       " 'originality': 'NOUN',\n",
       " 'nutrient': 'ADJ',\n",
       " 'functionally': 'ADV',\n",
       " '**ym': 'NOUN',\n",
       " 'gardens': 'NOUN',\n",
       " \"'58\": 'NUM',\n",
       " '7:45': 'NUM',\n",
       " 'freedom-loving': 'ADJ',\n",
       " 'fluttering': 'VERB',\n",
       " \"'stead\": 'ADV',\n",
       " 'Karipo': 'NOUN',\n",
       " 'ship': 'NOUN',\n",
       " 'Drive': 'NOUN',\n",
       " 'Fisk': 'NOUN',\n",
       " 'reinforced': 'VERB',\n",
       " 'Strindberg': 'NOUN',\n",
       " \"baseball's\": 'NOUN',\n",
       " 'Conseil': 'X',\n",
       " 'trachea': 'NOUN',\n",
       " 'Reichenberg': 'NOUN',\n",
       " 'Psychologically': 'ADV',\n",
       " 'Kurigalzu': 'NOUN',\n",
       " 'outweighed': 'VERB',\n",
       " \"Catholics'\": 'NOUN',\n",
       " 'lemonade': 'NOUN',\n",
       " 'vanilla': 'NOUN',\n",
       " '137': 'NUM',\n",
       " 'Northeastern': 'ADJ',\n",
       " 'sea-village': 'NOUN',\n",
       " 'pharmacy': 'NOUN',\n",
       " 'donor': 'NOUN',\n",
       " 'Windham': 'NOUN',\n",
       " 'drinking': 'VERB',\n",
       " 'whoop': 'NOUN',\n",
       " 'inter-relation': 'NOUN',\n",
       " 'somewheres': 'ADV',\n",
       " 'orchestrations': 'NOUN',\n",
       " '10-12': 'NUM',\n",
       " 'optimality': 'NOUN',\n",
       " 'Cliff': 'NOUN',\n",
       " 'dishonored': 'VERB',\n",
       " 'Ours': 'PRON',\n",
       " 'recklessness': 'NOUN',\n",
       " 'Voice': 'NOUN',\n",
       " 'disturber': 'NOUN',\n",
       " 'underdeveloped': 'ADJ',\n",
       " 'Stephens': 'NOUN',\n",
       " 'Existentialism': 'NOUN',\n",
       " '0.6': 'NUM',\n",
       " 'Maguires': 'NOUN',\n",
       " 'motherly': 'ADJ',\n",
       " 'investigating': 'VERB',\n",
       " 'samplers': 'NOUN',\n",
       " 'dictates': 'VERB',\n",
       " 'telephoning': 'VERB',\n",
       " 'donkey': 'NOUN',\n",
       " 'authorized': 'VERB',\n",
       " 'Sandburg': 'NOUN',\n",
       " 'vexed': 'VERB',\n",
       " 'threatening': 'VERB',\n",
       " 'operand': 'NOUN',\n",
       " 'dispatches': 'NOUN',\n",
       " 'textures': 'NOUN',\n",
       " 'Piraeus': 'NOUN',\n",
       " 'Evidence': 'NOUN',\n",
       " '$6,100,000,000': 'NOUN',\n",
       " 'cups': 'NOUN',\n",
       " 'Distillers': 'NOUN',\n",
       " '$.105': 'NOUN',\n",
       " 'adjourned': 'VERB',\n",
       " 'venerable': 'ADJ',\n",
       " 'vocalists': 'NOUN',\n",
       " 'mutational': 'ADJ',\n",
       " 'elegances': 'NOUN',\n",
       " 'Multiplication': 'NOUN',\n",
       " 'meanwhile': 'ADV',\n",
       " 'tough-looking': 'ADJ',\n",
       " 'Baltimore': 'NOUN',\n",
       " 'outcrops': 'NOUN',\n",
       " 'parole': 'NOUN',\n",
       " 'research': 'NOUN',\n",
       " 'NE': 'NOUN',\n",
       " 'review': 'NOUN',\n",
       " 'questions': 'NOUN',\n",
       " 'helpless': 'ADJ',\n",
       " 'infraction': 'NOUN',\n",
       " 'Jean-Paul': 'NOUN',\n",
       " 'endeavors': 'NOUN',\n",
       " \"Short's\": 'NOUN',\n",
       " 'Polls': 'NOUN',\n",
       " 'ogled': 'VERB',\n",
       " 'aggregate': 'ADJ',\n",
       " \"oystchers'll\": 'PRT',\n",
       " 'golfing': 'VERB',\n",
       " 'zigzagging': 'VERB',\n",
       " 'breakthroughs': 'NOUN',\n",
       " 'Iraj': 'NOUN',\n",
       " 'tangy': 'ADJ',\n",
       " 'sourdough': 'NOUN',\n",
       " 'hocking': 'VERB',\n",
       " 'Big': 'ADJ',\n",
       " 'ready': 'ADJ',\n",
       " 'saw-horse': 'NOUN',\n",
       " 'soda': 'NOUN',\n",
       " 'paraphrase': 'NOUN',\n",
       " 'resident': 'NOUN',\n",
       " 'dynamo': 'NOUN',\n",
       " 'Lodge': 'NOUN',\n",
       " 'Soloviev': 'NOUN',\n",
       " 'collecting': 'VERB',\n",
       " 'annihilation': 'NOUN',\n",
       " 'Doaty': 'NOUN',\n",
       " 'incorporation': 'NOUN',\n",
       " 'Flyer-Castle': 'NOUN',\n",
       " 'remain': 'VERB',\n",
       " 'screen': 'NOUN',\n",
       " 'versed': 'ADJ',\n",
       " 'Anti-Americanism': 'NOUN',\n",
       " 'phosphide': 'NOUN',\n",
       " 'jockey': 'NOUN',\n",
       " 'standing': 'VERB',\n",
       " 'uncap': 'VERB',\n",
       " 'Mighty': 'ADJ',\n",
       " 'dabbed': 'VERB',\n",
       " \"Tuttle's\": 'NOUN',\n",
       " 'ft.': 'NOUN',\n",
       " 'Vevay': 'NOUN',\n",
       " '600-yard': 'ADJ',\n",
       " 'contendere': 'X',\n",
       " 'orange': 'NOUN',\n",
       " 'scary': 'ADJ',\n",
       " 'cancel': 'VERB',\n",
       " '235': 'NUM',\n",
       " 'lobster': 'NOUN',\n",
       " 'home-bred': 'ADJ',\n",
       " 'nearly': 'ADV',\n",
       " 'picnicked': 'VERB',\n",
       " 'Alpers': 'NOUN',\n",
       " 'sentiments': 'NOUN',\n",
       " \"Montero's\": 'NOUN',\n",
       " 'concludes': 'VERB',\n",
       " '117': 'NUM',\n",
       " 'rescue': 'NOUN',\n",
       " 'complexes': 'NOUN',\n",
       " \"Brandon's\": 'NOUN',\n",
       " 'indisposition': 'NOUN',\n",
       " 'Post-Dispatch': 'NOUN',\n",
       " 'infantryman': 'NOUN',\n",
       " 'Cf.': 'VERB',\n",
       " 'Dec.': 'NOUN',\n",
       " 'cliffs': 'NOUN',\n",
       " 'janitor': 'NOUN',\n",
       " 'estrangement': 'NOUN',\n",
       " 'breakage': 'NOUN',\n",
       " 'Ligne': 'NOUN',\n",
       " 'aorta': 'NOUN',\n",
       " 'McAuliffe': 'NOUN',\n",
       " \"Dickens'\": 'NOUN',\n",
       " 'uneven': 'ADJ',\n",
       " 'Dried': 'VERB',\n",
       " 'shaker': 'NOUN',\n",
       " 'Gala': 'ADJ',\n",
       " 'disowned': 'VERB',\n",
       " 'signal-intensity': 'NOUN',\n",
       " 'iodinating': 'VERB',\n",
       " 'Afterward': 'ADV',\n",
       " 'starred': 'VERB',\n",
       " 'Shelley': 'NOUN',\n",
       " 'Twenty-second': 'ADJ',\n",
       " 'handling': 'NOUN',\n",
       " 'five-column': 'ADJ',\n",
       " 'Ready': 'ADJ',\n",
       " 'fortifications': 'NOUN',\n",
       " 'Quizzical': 'ADJ',\n",
       " '06-05': 'NUM',\n",
       " 'content': 'NOUN',\n",
       " 'spitting': 'VERB',\n",
       " '3:300': 'NUM',\n",
       " 'Althea': 'NOUN',\n",
       " 'Wis.': 'NOUN',\n",
       " 'guessing': 'VERB',\n",
       " 'Hong': 'NOUN',\n",
       " 'uh-huh': 'PRT',\n",
       " 'Nickel-iron': 'NOUN',\n",
       " \"Wheelock's\": 'NOUN',\n",
       " 'Babylonian': 'ADJ',\n",
       " 'vaudeville': 'NOUN',\n",
       " 'pandanus': 'NOUN',\n",
       " \"Anselm's\": 'NOUN',\n",
       " 'cosily': 'ADV',\n",
       " 'snubbing': 'VERB',\n",
       " 'pensioner': 'NOUN',\n",
       " 'Touch': 'NOUN',\n",
       " 'operationally': 'ADV',\n",
       " 'collision': 'NOUN',\n",
       " \"5/16''\": 'NOUN',\n",
       " 'rivals': 'NOUN',\n",
       " 'Roman-camp': 'ADJ',\n",
       " 'choppy': 'ADJ',\n",
       " 'non-resistants': 'NOUN',\n",
       " 'fifty-odd': 'NUM',\n",
       " 'glamour': 'NOUN',\n",
       " 'hygiene': 'NOUN',\n",
       " 'mirror': 'NOUN',\n",
       " 'radio-TV': 'NOUN',\n",
       " 'cinder': 'NOUN',\n",
       " 'religiousness': 'NOUN',\n",
       " 'admonitions': 'NOUN',\n",
       " 're-emphasise': 'VERB',\n",
       " 'Swelling': 'VERB',\n",
       " 'Okada': 'NOUN',\n",
       " '1905': 'NUM',\n",
       " 'sulphur': 'NOUN',\n",
       " 'ab': 'NOUN',\n",
       " 'simmer': 'VERB',\n",
       " 'Reverdy': 'NOUN',\n",
       " 'play-off': 'NOUN',\n",
       " 'Players': 'NOUN',\n",
       " 'engineer': 'NOUN',\n",
       " 'instruct': 'VERB',\n",
       " 'Greg': 'NOUN',\n",
       " 'English-Dutch': 'ADJ',\n",
       " 'buckaroos': 'NOUN',\n",
       " 'Dillinger': 'NOUN',\n",
       " 'rat-a-tat-tatty': 'ADJ',\n",
       " 'Quickly': 'ADV',\n",
       " 'bay': 'NOUN',\n",
       " 'contrivances': 'NOUN',\n",
       " 'There': 'PRT',\n",
       " 'disoriented': 'VERB',\n",
       " 'face-lifting': 'NOUN',\n",
       " 'rapidity': 'NOUN',\n",
       " 'sash': 'NOUN',\n",
       " 'Bert': 'NOUN',\n",
       " 'anorthic': 'ADJ',\n",
       " 'tooth': 'NOUN',\n",
       " 'rake': 'NOUN',\n",
       " 'liners': 'NOUN',\n",
       " 'Silas': 'NOUN',\n",
       " 'thirty-four': 'NUM',\n",
       " 'Ozzie': 'NOUN',\n",
       " 'rages': 'NOUN',\n",
       " 'alimony': 'NOUN',\n",
       " 'pyocanea': 'NOUN',\n",
       " 'access': 'NOUN',\n",
       " 'straddling': 'VERB',\n",
       " 'auf': 'X',\n",
       " 'Wings': 'NOUN',\n",
       " 'honored': 'VERB',\n",
       " 'reunite': 'VERB',\n",
       " 'ad': 'NOUN',\n",
       " 'unpack': 'VERB',\n",
       " 'formulation': 'NOUN',\n",
       " 'Haliburton': 'NOUN',\n",
       " 'orphan': 'NOUN',\n",
       " 'eighth': 'ADJ',\n",
       " 'face-saving': 'ADJ',\n",
       " 'construction': 'NOUN',\n",
       " 'Halfback': 'NOUN',\n",
       " 'proximate': 'ADJ',\n",
       " 'booklets': 'NOUN',\n",
       " \"Mark's\": 'NOUN',\n",
       " 'longhorns': 'NOUN',\n",
       " 'heterogeneous': 'ADJ',\n",
       " 'admonished': 'VERB',\n",
       " 'Consonantal': 'ADJ',\n",
       " 'railroad': 'NOUN',\n",
       " 'EEG': 'NOUN',\n",
       " 'Revolutionary': 'ADJ',\n",
       " '514': 'NUM',\n",
       " 'niece': 'NOUN',\n",
       " 'Lil': 'NOUN',\n",
       " 'Pontiac': 'NOUN',\n",
       " 'S-20': 'NOUN',\n",
       " 'decision-making': 'NOUN',\n",
       " 'Casbah': 'NOUN',\n",
       " 'boom-boom-boom': 'PRT',\n",
       " 'discourses': 'NOUN',\n",
       " 'Arthur': 'NOUN',\n",
       " 'summarize': 'VERB',\n",
       " 'Perrin': 'NOUN',\n",
       " 'abode': 'NOUN',\n",
       " 'Negro': 'NOUN',\n",
       " 'Advise': 'VERB',\n",
       " 'boosted': 'VERB',\n",
       " 'hypothyroidism': 'NOUN',\n",
       " 'clamshell': 'NOUN',\n",
       " 'multi-year': 'ADJ',\n",
       " 'converted': 'VERB',\n",
       " 'onct': 'ADV',\n",
       " \"nation's\": 'NOUN',\n",
       " 'dipole': 'ADJ',\n",
       " 'hospitable': 'ADJ',\n",
       " 'enlarge': 'VERB',\n",
       " 'cloddishness': 'NOUN',\n",
       " 'Eugene': 'NOUN',\n",
       " 'workings': 'NOUN',\n",
       " 'WTV': 'NOUN',\n",
       " 'fold': 'NOUN',\n",
       " 'tendered': 'VERB',\n",
       " 'cuisine': 'X',\n",
       " 'prerequisite': 'NOUN',\n",
       " 'swanky': 'ADJ',\n",
       " 'pennant': 'NOUN',\n",
       " 'antecedents': 'NOUN',\n",
       " 'courtesy': 'NOUN',\n",
       " 'Greentree': 'NOUN',\n",
       " 'panelization': 'NOUN',\n",
       " 'Somerville': 'NOUN',\n",
       " '2:31.3-:35.3': 'NUM',\n",
       " 'Nennius': 'NOUN',\n",
       " 'explosively': 'ADV',\n",
       " 'odd-lot': 'NOUN',\n",
       " 'one-story': 'ADJ',\n",
       " 'straggled': 'VERB',\n",
       " 'disposition': 'NOUN',\n",
       " 'Peony': 'NOUN',\n",
       " 'Bridget': 'NOUN',\n",
       " 'oppressive': 'ADJ',\n",
       " 'littered': 'VERB',\n",
       " 'shaved': 'VERB',\n",
       " 'cluck': 'NOUN',\n",
       " \"citizen's\": 'NOUN',\n",
       " 'Salish': 'NOUN',\n",
       " 'hostilities': 'NOUN',\n",
       " 'interacting': 'VERB',\n",
       " \"patient's\": 'NOUN',\n",
       " 'Benched': 'VERB',\n",
       " \"sheriff's\": 'NOUN',\n",
       " 'sneaker': 'NOUN',\n",
       " 'orgies': 'NOUN',\n",
       " 'deformity': 'NOUN',\n",
       " 'overdoing': 'VERB',\n",
       " 'daily': 'ADV',\n",
       " 'Fontainebleau': 'NOUN',\n",
       " 'sets': 'NOUN',\n",
       " 'Stick': 'VERB',\n",
       " 'Impressive': 'ADJ',\n",
       " 'archeological': 'ADJ',\n",
       " 'surgery': 'NOUN',\n",
       " 'Implements': 'NOUN',\n",
       " 'bees': 'NOUN',\n",
       " 'babbled': 'VERB',\n",
       " 'Pietro': 'NOUN',\n",
       " 'ethicist': 'NOUN',\n",
       " 'spellbound': 'VERB',\n",
       " 'Mahone': 'NOUN',\n",
       " 'never': 'ADV',\n",
       " 'herbs': 'NOUN',\n",
       " 'strategic': 'ADJ',\n",
       " \"another's\": 'DET',\n",
       " 'Mecca': 'NOUN',\n",
       " 'navy-blue': 'ADJ',\n",
       " 'mon': 'X',\n",
       " 'cult': 'NOUN',\n",
       " 'comely': 'ADJ',\n",
       " 'assailant': 'NOUN',\n",
       " 'monde': 'X',\n",
       " 'quo': 'X',\n",
       " 'mockery': 'NOUN',\n",
       " 'yoke': 'NOUN',\n",
       " 'uninjured': 'ADJ',\n",
       " 'designations': 'NOUN',\n",
       " 'Weep': 'VERB',\n",
       " 'Hammond': 'NOUN',\n",
       " 'toilets': 'NOUN',\n",
       " '21-year-old': 'ADJ',\n",
       " 'card': 'NOUN',\n",
       " 'leadsman': 'NOUN',\n",
       " 'shatter': 'VERB',\n",
       " 'Preludes': 'NOUN',\n",
       " 'microcosm': 'NOUN',\n",
       " 'aleck': 'NOUN',\n",
       " 'deduced': 'VERB',\n",
       " 'smart': 'ADJ',\n",
       " 'hungry': 'ADJ',\n",
       " 'Bragg': 'NOUN',\n",
       " 'gate': 'NOUN',\n",
       " 'correctly': 'ADV',\n",
       " 'permitting': 'VERB',\n",
       " 'apt': 'ADJ',\n",
       " 'Howe': 'NOUN',\n",
       " 'tuberculosis': 'NOUN',\n",
       " 'globes': 'NOUN',\n",
       " 'screenings': 'NOUN',\n",
       " 'autocrats': 'NOUN',\n",
       " 'northwest': 'NOUN',\n",
       " 'christianizing': 'VERB',\n",
       " 'coaches': 'NOUN',\n",
       " 'Osaka': 'NOUN',\n",
       " 'foreheads': 'NOUN',\n",
       " 'Construct': 'VERB',\n",
       " 'Because': 'ADP',\n",
       " 'blown': 'VERB',\n",
       " 'Seymour': 'NOUN',\n",
       " 'opened': 'VERB',\n",
       " 'contended': 'VERB',\n",
       " 'bout': 'NOUN',\n",
       " 'Peck': 'NOUN',\n",
       " 'baby-sitter': 'NOUN',\n",
       " 'Squadrons': 'NOUN',\n",
       " 'pater': 'X',\n",
       " 'Hurts': 'NOUN',\n",
       " 'floor-to-ceiling': 'ADJ',\n",
       " 'loose': 'ADJ',\n",
       " 'exceeds': 'VERB',\n",
       " 'possesses': 'VERB',\n",
       " 'artifice': 'NOUN',\n",
       " 'tear': 'VERB',\n",
       " '5-percent': 'NOUN',\n",
       " 'Butlers': 'NOUN',\n",
       " 'Musical': 'ADJ',\n",
       " 'devoutly': 'ADV',\n",
       " 'apogee': 'NOUN',\n",
       " 'malady': 'NOUN',\n",
       " 'tasting': 'VERB',\n",
       " 'mounted': 'VERB',\n",
       " 'Lawrence': 'NOUN',\n",
       " '1628/29': 'NUM',\n",
       " 'freeman': 'NOUN',\n",
       " 'tidying': 'VERB',\n",
       " 'Schweizer': 'NOUN',\n",
       " 'Jazz': 'NOUN',\n",
       " 'Gioconda': 'NOUN',\n",
       " 'Forget': 'VERB',\n",
       " 'vocational-advancement': 'NOUN',\n",
       " \"Massachusetts'\": 'NOUN',\n",
       " 'interlibrary': 'ADJ',\n",
       " 'relic': 'NOUN',\n",
       " 'wakened': 'VERB',\n",
       " 'elongated': 'VERB',\n",
       " 'Moloch': 'NOUN',\n",
       " 'myself': 'PRON',\n",
       " 'Salida': 'NOUN',\n",
       " 'sunder': 'VERB',\n",
       " 'chirped': 'VERB',\n",
       " 'murderous': 'ADJ',\n",
       " '$37': 'NOUN',\n",
       " 'wood': 'NOUN',\n",
       " 'seriously': 'ADV',\n",
       " 'Wesson': 'NOUN',\n",
       " 'oversubscribed': 'VERB',\n",
       " 'large-scale': 'NOUN',\n",
       " 'extirpated': 'VERB',\n",
       " 'fried': 'VERB',\n",
       " 'Despite': 'ADP',\n",
       " \"Oliver's\": 'NOUN',\n",
       " 'Triandos': 'NOUN',\n",
       " \"Cimabue's\": 'NOUN',\n",
       " 'Ken': 'NOUN',\n",
       " \"chapter's\": 'NOUN',\n",
       " 'astute': 'ADJ',\n",
       " \"Gracie's\": 'NOUN',\n",
       " 'PWA': 'NOUN',\n",
       " 'unimaginable': 'ADJ',\n",
       " 'anatomic': 'ADJ',\n",
       " 'informant': 'NOUN',\n",
       " 'unhappily': 'ADV',\n",
       " 'Dangling': 'VERB',\n",
       " 'girl': 'NOUN',\n",
       " '12-1/2-inch': 'ADJ',\n",
       " \"C'mon\": 'PRT',\n",
       " \"home's\": 'NOUN',\n",
       " 'detached': 'VERB',\n",
       " 'Hargett': 'NOUN',\n",
       " 'Lewis': 'NOUN',\n",
       " 'Kassem': 'NOUN',\n",
       " 'vegetables': 'NOUN',\n",
       " 'Decorating': 'VERB',\n",
       " 'massed': 'VERB',\n",
       " 'coasted': 'VERB',\n",
       " 'Encourage': 'VERB',\n",
       " 'crowned': 'VERB',\n",
       " \"Phil's\": 'NOUN',\n",
       " 'Lobar': 'ADJ',\n",
       " 'Corinthian': 'ADJ',\n",
       " 'Lemuel': 'NOUN',\n",
       " 'comic': 'ADJ',\n",
       " 'Jefferson': 'NOUN',\n",
       " 'Nationalism': 'NOUN',\n",
       " 'drugstore': 'NOUN',\n",
       " 'Dimaggio': 'NOUN',\n",
       " 'Leadership': 'NOUN',\n",
       " 'larks': 'NOUN',\n",
       " 'sorghum': 'NOUN',\n",
       " 'Patagonians': 'NOUN',\n",
       " \"s'accuse\": 'X',\n",
       " 'acid': 'NOUN',\n",
       " 'Concerto': 'NOUN',\n",
       " 'waffles': 'NOUN',\n",
       " 'logs': 'NOUN',\n",
       " 'guerrillas': 'NOUN',\n",
       " \"film's\": 'NOUN',\n",
       " 'birdbath': 'NOUN',\n",
       " \"Fogg's\": 'NOUN',\n",
       " 'propionate': 'NOUN',\n",
       " 'ruling-class': 'NOUN',\n",
       " 'emeralds': 'NOUN',\n",
       " 'Fike': 'NOUN',\n",
       " 'vise': 'NOUN',\n",
       " 'Colonna': 'NOUN',\n",
       " 'startled-horse': 'NOUN',\n",
       " 'purposes': 'NOUN',\n",
       " 'celebration': 'NOUN',\n",
       " 'grandson': 'NOUN',\n",
       " 'caller': 'NOUN',\n",
       " '2.8': 'NUM',\n",
       " 'equine': 'NOUN',\n",
       " 'tipping': 'VERB',\n",
       " 'reckon': 'VERB',\n",
       " 'Tao': 'NOUN',\n",
       " 'overcoats': 'NOUN',\n",
       " 'conforms': 'VERB',\n",
       " '500': 'NUM',\n",
       " 'arms-making': 'NOUN',\n",
       " 'splash': 'NOUN',\n",
       " 'supervise': 'VERB',\n",
       " 'pungently': 'ADV',\n",
       " 'declarations': 'NOUN',\n",
       " 'dunes': 'NOUN',\n",
       " 'comprises': 'VERB',\n",
       " 'acre-feet': 'NOUN',\n",
       " '2-3/4': 'NUM',\n",
       " 'coastal': 'ADJ',\n",
       " 'unilateral': 'ADJ',\n",
       " 'psychopathic': 'ADJ',\n",
       " 'frightfully': 'ADV',\n",
       " 'Montgomery': 'NOUN',\n",
       " '$7,500,000': 'NOUN',\n",
       " 'chipping': 'VERB',\n",
       " 'quixotic': 'ADJ',\n",
       " 'infected': 'VERB',\n",
       " 'cues': 'NOUN',\n",
       " 'sister': 'NOUN',\n",
       " 'consequent': 'ADJ',\n",
       " 'woodworking': 'VERB',\n",
       " '50': 'NUM',\n",
       " \"Poor's\": 'NOUN',\n",
       " 'Ambler': 'NOUN',\n",
       " 'realty': 'NOUN',\n",
       " 'ExPe': 'NOUN',\n",
       " 'cetera': 'X',\n",
       " 'unnatural': 'ADJ',\n",
       " 'clay': 'NOUN',\n",
       " 'cannibals': 'NOUN',\n",
       " 'half-gourd': 'NOUN',\n",
       " \"else's\": 'PRT',\n",
       " \"organization's\": 'NOUN',\n",
       " '2:34.2': 'NUM',\n",
       " 'ambivalent': 'ADJ',\n",
       " 'hypoactive': 'ADJ',\n",
       " 'outdated': 'VERB',\n",
       " 'Boismassif': 'NOUN',\n",
       " 'regal': 'ADJ',\n",
       " 'wage-price': 'NOUN',\n",
       " 'Sahara': 'NOUN',\n",
       " 'denomination': 'NOUN',\n",
       " 'detector': 'NOUN',\n",
       " 'Naktong': 'NOUN',\n",
       " 'treaty-making': 'NOUN',\n",
       " 'rye': 'NOUN',\n",
       " 'boites': 'X',\n",
       " 'Guilford-Martin': 'NOUN',\n",
       " 'candy': 'NOUN',\n",
       " 'Beads': 'NOUN',\n",
       " '12-month': 'ADJ',\n",
       " 'Homeric': 'ADJ',\n",
       " 'pseudophloem': 'NOUN',\n",
       " \"Perier's\": 'NOUN',\n",
       " 'goldfish': 'NOUN',\n",
       " 'granddaughter': 'NOUN',\n",
       " 'landau': 'NOUN',\n",
       " \"Beethoven's\": 'NOUN',\n",
       " 'sizes': 'NOUN',\n",
       " \"1/2''\": 'NOUN',\n",
       " 'Cedric': 'NOUN',\n",
       " 'outfitted': 'VERB',\n",
       " 'crops': 'NOUN',\n",
       " 'ion': 'NOUN',\n",
       " 'slapstick': 'NOUN',\n",
       " 'Property': 'NOUN',\n",
       " 'Message': 'NOUN',\n",
       " 'propulsion': 'NOUN',\n",
       " 'Oopsie-Cola': 'NOUN',\n",
       " 'wiping': 'VERB',\n",
       " 'Penny': 'NOUN',\n",
       " 'disillusionment': 'NOUN',\n",
       " 'Benjamin': 'NOUN',\n",
       " 'greatness': 'NOUN',\n",
       " 'rockbound': 'ADJ',\n",
       " 'LaSalle': 'NOUN',\n",
       " 'threats': 'NOUN',\n",
       " 'excessive': 'ADJ',\n",
       " 'damned': 'VERB',\n",
       " 'untracked': 'ADJ',\n",
       " 'fielding': 'VERB',\n",
       " 'hack': 'NOUN',\n",
       " 'unfolded': 'VERB',\n",
       " 'Totalitarianism': 'NOUN',\n",
       " 'Elliott': 'NOUN',\n",
       " 'stopped': 'VERB',\n",
       " 'shod': 'VERB',\n",
       " 'theoretical': 'ADJ',\n",
       " 'institution': 'NOUN',\n",
       " 'activation': 'NOUN',\n",
       " 'inapplicable': 'ADJ',\n",
       " 'electrostatic': 'ADJ',\n",
       " 'contact': 'NOUN',\n",
       " 'Greenwood': 'NOUN',\n",
       " 'beebread': 'NOUN',\n",
       " 'misshapen': 'ADJ',\n",
       " 'apotheosis': 'NOUN',\n",
       " 'meal-to-meal': 'ADJ',\n",
       " 'fortitude': 'NOUN',\n",
       " 'fourteen-nation': 'ADJ',\n",
       " 'Eternity': 'NOUN',\n",
       " 'Carre': 'NOUN',\n",
       " 'handbag': 'NOUN',\n",
       " 'moderation': 'NOUN',\n",
       " 'residences': 'NOUN',\n",
       " 'squirted': 'VERB',\n",
       " 'Mundt': 'NOUN',\n",
       " 'gritty': 'ADJ',\n",
       " 'Massacres': 'NOUN',\n",
       " 'autopsied': 'VERB',\n",
       " 'relatives': 'NOUN',\n",
       " 'bellowing': 'VERB',\n",
       " 'investigation': 'NOUN',\n",
       " 'prize-fight': 'NOUN',\n",
       " 'McCormack': 'NOUN',\n",
       " 'bundled': 'VERB',\n",
       " 'symphony': 'NOUN',\n",
       " 'imagine': 'VERB',\n",
       " 'brief': 'ADJ',\n",
       " '80-degrees-C': 'NOUN',\n",
       " 'rangers': 'NOUN',\n",
       " 'fractionated': 'VERB',\n",
       " 'wanna': 'VERB',\n",
       " 'helpfully': 'ADV',\n",
       " 'orgasms': 'NOUN',\n",
       " 'diamond': 'NOUN',\n",
       " 'Kittredge': 'NOUN',\n",
       " 'brushed': 'VERB',\n",
       " 'exceed': 'VERB',\n",
       " 'pro-U.N.F.P.': 'ADJ',\n",
       " 'McNamara': 'NOUN',\n",
       " 'cinders': 'NOUN',\n",
       " 'adds': 'VERB',\n",
       " 'harmonization': 'NOUN',\n",
       " 'propaganda': 'NOUN',\n",
       " 'infrequently': 'ADV',\n",
       " 'Gisors': 'NOUN',\n",
       " '1,253': 'NUM',\n",
       " 'double-': 'ADJ',\n",
       " 'economize': 'VERB',\n",
       " 'oath-taking': 'ADJ',\n",
       " 'contributes': 'VERB',\n",
       " 'Facilitatory': 'ADJ',\n",
       " 'Erie': 'NOUN',\n",
       " 'singer': 'NOUN',\n",
       " 'pond': 'NOUN',\n",
       " 'threefold': 'X',\n",
       " 'upturn': 'NOUN',\n",
       " 'Lehman': 'NOUN',\n",
       " 'emptiness': 'NOUN',\n",
       " 'bilateral': 'ADJ',\n",
       " 'Babylonians': 'NOUN',\n",
       " 'Buena': 'NOUN',\n",
       " 'governors': 'NOUN',\n",
       " 'suffocated': 'VERB',\n",
       " 'Pololu': 'NOUN',\n",
       " 'mass': 'NOUN',\n",
       " 'fuzzy': 'ADJ',\n",
       " 'arrange': 'VERB',\n",
       " 'social-welfare': 'NOUN',\n",
       " 'indelicate': 'ADJ',\n",
       " 'answerable': 'ADJ',\n",
       " 'chow': 'NOUN',\n",
       " 'spares': 'VERB',\n",
       " 'Brooklyn': 'NOUN',\n",
       " '1065': 'NUM',\n",
       " 'Solly': 'NOUN',\n",
       " 'Doctor': 'NOUN',\n",
       " 'cadenza': 'NOUN',\n",
       " 'involvements': 'NOUN',\n",
       " 'demonstrating': 'VERB',\n",
       " 'detectives': 'NOUN',\n",
       " 'wrapping': 'VERB',\n",
       " 'pilgrimage': 'NOUN',\n",
       " 'no-one': 'NOUN',\n",
       " 'seedless': 'ADJ',\n",
       " 'dialectical': 'ADJ',\n",
       " 'barbiturate': 'NOUN',\n",
       " 'Squibb': 'NOUN',\n",
       " 'subroutines': 'NOUN',\n",
       " 'Meeker': 'NOUN',\n",
       " 'brynge': 'VERB',\n",
       " 'Future': 'ADJ',\n",
       " 'Straight': 'ADJ',\n",
       " \"moment's\": 'NOUN',\n",
       " 'ribald': 'ADJ',\n",
       " 'Failure': 'NOUN',\n",
       " 'stirringly': 'ADV',\n",
       " 'heredity': 'NOUN',\n",
       " 'memorialized': 'VERB',\n",
       " 'wrings': 'VERB',\n",
       " 'company-paid': 'ADJ',\n",
       " 'fantasy': 'NOUN',\n",
       " 'Heavily': 'ADV',\n",
       " 'mos.': 'NOUN',\n",
       " '2.44': 'NUM',\n",
       " 'bandwidth': 'NOUN',\n",
       " 'Campaigning': 'VERB',\n",
       " 'stabilities': 'NOUN',\n",
       " 'choices': 'NOUN',\n",
       " 'loathing': 'VERB',\n",
       " 'paxam': 'X',\n",
       " ...}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfc_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions with a Model\n",
    "The helper functions provided below interface with Pomegranate network models & the mocked MFCTagger to take advantage of the [missing value](http://pomegranate.readthedocs.io/en/latest/nan.html) functionality in Pomegranate through a simple sequence decoding function. Run these functions, then run the next cell to see some of the predictions made by the MFC tagger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_unknown(sequence):\n",
    "    \"\"\"Return a copy of the input sequence where each unknown word is replaced\n",
    "    by the literal string value 'nan'. Pomegranate will ignore these values\n",
    "    during computation.\n",
    "    \"\"\"\n",
    "    return [w if w in data.training_set.vocab else 'nan' for w in sequence]\n",
    "\n",
    "def simplify_decoding(X, model):\n",
    "    \"\"\"X should be a 1-D sequence of observations for the model to predict\"\"\"\n",
    "    _, state_path = model.viterbi(replace_unknown(X))\n",
    "    return [state[1].name for state in state_path[1:-1]]  # do not show the start/end state predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Decoding Sequences with MFC Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Key: b100-23173\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['NOUN', '.', 'ADV', '.', 'VERB', 'ADP', 'ADP', 'NOUN', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'ADJ', 'CONJ', 'ADV', 'ADJ', 'NOUN', '.', 'NOUN', '.', 'PRON', 'VERB', 'ADV', 'ADP', 'DET', 'ADJ', 'NOUN', 'CONJ', 'PRON', 'PRON', 'VERB', 'VERB', 'PRT', 'VERB', 'ADV', 'ADP', 'NOUN', 'PRT', 'NOUN', 'ADP', 'NOUN', '.', 'ADV', 'PRON', 'VERB', 'ADP', 'NOUN', 'NOUN', 'ADP', '<MISSING>', '<MISSING>', 'NOUN', 'PRT', 'ADP', 'DET', '<MISSING>', 'NOUN', 'ADP', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('NOUN', '.', 'ADV', '.', 'VERB', 'ADP', 'DET', 'NOUN', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', 'ADP', 'NOUN', 'ADJ', 'CONJ', 'ADV', 'ADJ', 'NOUN', '.', 'NOUN', '.', 'PRON', 'VERB', 'ADV', 'ADV', 'DET', 'ADJ', 'NOUN', 'CONJ', 'PRON', 'PRON', 'VERB', 'VERB', 'PRT', 'VERB', 'ADV', 'ADP', 'NOUN', 'ADP', 'NOUN', 'ADP', 'NOUN', '.', 'ADV', 'PRON', 'VERB', 'ADP', 'NOUN', 'NOUN', 'ADP', 'NOUN', 'NOUN', 'NOUN', 'ADV', 'ADP', 'DET', 'NOUN', 'NOUN', 'ADP', 'NOUN', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-11442\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'VERB', 'ADV', 'VERB', 'PRT', '.', 'CONJ', 'ADP', 'DET', 'PRON', 'VERB', 'ADV', 'VERB', 'DET', 'ADJ', '<MISSING>', 'NOUN', 'DET', 'NOUN', 'VERB', 'PRT', 'DET', 'ADJ', 'NOUN', '.', 'DET', 'ADJ', 'NOUN', 'ADP', 'PRON', 'VERB', 'VERB', 'ADP', '<MISSING>', 'NOUN', '.', '.', 'CONJ', 'DET', '<MISSING>', 'NOUN', 'ADP', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('DET', 'NOUN', 'ADP', 'DET', 'NOUN', 'VERB', 'VERB', 'ADV', 'VERB', 'PRT', '.', 'CONJ', 'ADP', 'DET', 'PRON', 'VERB', 'ADV', 'VERB', 'DET', 'ADJ', 'X', 'NOUN', 'DET', 'NOUN', 'VERB', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'DET', 'ADJ', 'NOUN', 'ADP', 'PRON', 'VERB', 'VERB', 'ADP', 'ADJ', 'NOUN', '.', '.', 'CONJ', 'DET', 'NOUN', 'NOUN', 'ADP', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-20697\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['PRON', 'VERB', '.', 'ADP', 'NOUN', '.', 'DET', 'ADJ', 'NOUN', 'ADP', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('PRON', 'VERB', '.', 'ADP', 'NOUN', '.', 'DET', 'ADJ', 'NOUN', 'ADP', 'NOUN', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-36343\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['DET', 'NOUN', 'VERB', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('DET', 'NOUN', 'VERB', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-48973\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['ADP', 'NOUN', 'PRON', 'VERB', 'VERB', 'NOUN', 'ADV', 'ADP', 'VERB', 'DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'DET', 'ADJ', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('ADP', 'NOUN', 'PRON', 'VERB', 'VERB', 'NOUN', 'ADV', 'ADP', 'VERB', 'DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'DET', 'ADJ', '.')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in data.testing_set.keys[:5]:\n",
    "    print(\"Sentence Key: {}\\n\".format(key))\n",
    "    print(\"Predicted labels:\\n-----------------\")\n",
    "    print(simplify_decoding(data.sentences[key].words, mfc_model))\n",
    "    print()\n",
    "    print(\"Actual labels:\\n--------------\")\n",
    "    print(data.sentences[key].tags)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Model Accuracy\n",
    "\n",
    "The function below will evaluate the accuracy of the MFC tagger on the collection of all sentences from a text corpus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(X, Y, model):\n",
    "    \"\"\"Calculate the prediction accuracy by using the model to decode each sequence\n",
    "    in the input X and comparing the prediction with the true labels in Y.\n",
    "    \n",
    "    The X should be an array whose first dimension is the number of sentences to test,\n",
    "    and each element of the array should be an iterable of the words in the sequence.\n",
    "    The arrays X and Y should have the exact same shape.\n",
    "    \n",
    "    X = [(\"See\", \"Spot\", \"run\"), (\"Run\", \"Spot\", \"run\", \"fast\"), ...]\n",
    "    Y = [(), (), ...]\n",
    "    \"\"\"\n",
    "    correct = total_predictions = 0\n",
    "    for observations, actual_tags in zip(X, Y):\n",
    "        \n",
    "        # The model.viterbi call in simplify_decoding will return None if the HMM\n",
    "        # raises an error (for example, if a test sentence contains a word that\n",
    "        # is out of vocabulary for the training set). Any exception counts the\n",
    "        # full sentence as an error (which makes this a conservative estimate).\n",
    "        try:\n",
    "            most_likely_tags = simplify_decoding(observations, model)\n",
    "            correct += sum(p == t for p, t in zip(most_likely_tags, actual_tags))\n",
    "        except:\n",
    "            pass\n",
    "        total_predictions += len(observations)\n",
    "    return correct / total_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the accuracy of the MFC tagger\n",
    "Run the next cell to evaluate the accuracy of the tagger on the training and test corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy mfc_model: 95.73%\n",
      "testing accuracy mfc_model: 92.93%\n"
     ]
    }
   ],
   "source": [
    "mfc_training_acc = accuracy(data.training_set.X, data.training_set.Y, mfc_model)\n",
    "print(\"training accuracy mfc_model: {:.2f}%\".format(100 * mfc_training_acc))\n",
    "\n",
    "mfc_testing_acc = accuracy(data.testing_set.X, data.testing_set.Y, mfc_model)\n",
    "print(\"testing accuracy mfc_model: {:.2f}%\".format(100 * mfc_testing_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build an HMM tagger\n",
    "---\n",
    "The HMM tagger has one hidden state for each possible tag, and parameterized by two distributions: the emission probabilties giving the conditional probability of observing a given **word** from each hidden state, and the transition probabilities giving the conditional probability of moving between **tags** during the sequence.\n",
    "\n",
    "We will also estimate the starting probability distribution (the probability of each **tag** being the first tag in a sequence), and the terminal probability distribution (the probability of each **tag** being the last tag in a sequence).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPLEMENTATION: Unigram Counts\n",
    "\n",
    "Complete the function below to estimate the co-occurrence frequency of each symbol over all of the input sequences. The unigram probabilities in our HMM model are estimated from the formula below, where N is the total number of samples in the input. (You only need to compute the counts for now.)\n",
    "\n",
    "$$P(tag_1) = \\frac{C(tag_1)}{N}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your tag unigrams look good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unigram_counts(sequences):\n",
    "    \"\"\"Return a dictionary keyed to each unique value in the input sequence list that\n",
    "    counts the number of occurrences of the value in the sequences list. The sequences\n",
    "    collection should be a 2-dimensional array.\n",
    "    \n",
    "    For example, if the tag NOUN appears 275558 times over all the input sequences,\n",
    "    then you should return a dictionary such that your_unigram_counts[NOUN] == 275558.\n",
    "    \"\"\"\n",
    "    # TODO: Finish this function!\n",
    "        \n",
    "    # problem is that you have many sequences\n",
    "    # also you have to divide by N\n",
    "    unigram_counts = {}\n",
    "\n",
    "    for i, sentence in enumerate(sequences):\n",
    "        for j, y in enumerate(sentence):\n",
    "            if y in unigram_counts:\n",
    "                unigram_counts[y] += 1\n",
    "            else:\n",
    "                unigram_counts[y] = 1\n",
    "    \n",
    "    return unigram_counts\n",
    "\n",
    "# TODO: call unigram_counts with a list of tag sequences from the training set\n",
    "\n",
    "tag_unigrams = unigram_counts(data.training_set.Y)\n",
    "\n",
    "assert set(tag_unigrams.keys()) == data.training_set.tagset, \\\n",
    "       \"Uh oh. It looks like your tag counts doesn't include all the tags!\"\n",
    "assert min(tag_unigrams, key=tag_unigrams.get) == 'X', \\\n",
    "       \"Hmmm...'X' is expected to be the least common class\"\n",
    "assert max(tag_unigrams, key=tag_unigrams.get) == 'NOUN', \\\n",
    "       \"Hmmm...'NOUN' is expected to be the most common class\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your tag unigrams look good!</div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPLEMENTATION: Bigram Counts\n",
    "\n",
    "Complete the function below to estimate the co-occurrence frequency of each pair of symbols in each of the input sequences. These counts are used in the HMM model to estimate the bigram probability of two tags from the frequency counts according to the formula: $$P(tag_2|tag_1) = \\frac{C(tag_2|tag_1)}{C(tag_2)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your tag bigrams look good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def bigram_counts(sequences):\n",
    "    \"\"\"Return a dictionary keyed to each unique PAIR of values in the input sequences\n",
    "    list that counts the number of occurrences of pair in the sequences list. The input\n",
    "    should be a 2-dimensional array.\n",
    "    \n",
    "    For example, if the pair of tags (NOUN, VERB) appear 61582 times, then you should\n",
    "    return a dictionary such that your_bigram_counts[(NOUN, VERB)] == 61582\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    bigram_counts = {}\n",
    "    \n",
    "    for i, sentence in enumerate(sequences):\n",
    "        for y in range(len(sentence) - 1):\n",
    "            if (sentence[y], sentence[y+1]) in bigram_counts:\n",
    "                bigram_counts[(sentence[y], sentence[y+1])] += 1\n",
    "            else:\n",
    "                bigram_counts[(sentence[y], sentence[y+1])] = 1\n",
    "    \n",
    "    \n",
    "    \n",
    "    return bigram_counts\n",
    "\n",
    "# TODO: call bigram_counts with a list of tag sequences from the training set\n",
    "tag_bigrams = bigram_counts(data.training_set.Y)\n",
    "\n",
    "assert len(tag_bigrams) == 144, \\\n",
    "       \"Uh oh. There should be 144 pairs of bigrams (12 tags x 12 tags)\"\n",
    "assert min(tag_bigrams, key=tag_bigrams.get) in [('X', 'NUM'), ('PRON', 'X')], \\\n",
    "       \"Hmmm...The least common bigram should be one of ('X', 'NUM') or ('PRON', 'X').\"\n",
    "assert max(tag_bigrams, key=tag_bigrams.get) in [('DET', 'NOUN')], \\\n",
    "       \"Hmmm...('DET', 'NOUN') is expected to be the most common bigram.\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your tag bigrams look good!</div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPLEMENTATION: Sequence Starting Counts\n",
    "Complete the code below to estimate the bigram probabilities of a sequence starting with each tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your starting tag counts look good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def starting_counts(sequences):\n",
    "    \"\"\"Return a dictionary keyed to each unique value in the input sequences list\n",
    "    that counts the number of occurrences where that value is at the beginning of\n",
    "    a sequence.\n",
    "    \n",
    "    For example, if 8093 sequences start with NOUN, then you should return a\n",
    "    dictionary such that your_starting_counts[NOUN] == 8093\n",
    "    \"\"\"\n",
    "    \n",
    "    starting_counts = {}\n",
    "    \n",
    "    for i, sentence in enumerate(sequences):\n",
    "        if sentence[0] in starting_counts:\n",
    "            starting_counts[sentence[0]] += 1\n",
    "        else:\n",
    "            starting_counts[sentence[0]] = 1\n",
    "\n",
    "\n",
    "    return starting_counts\n",
    "\n",
    "# TODO: Calculate the count of each tag starting a sequence\n",
    "tag_starts = starting_counts(data.training_set.Y)\n",
    "\n",
    "assert len(tag_starts) == 12, \"Uh oh. There should be 12 tags in your dictionary.\"\n",
    "assert min(tag_starts, key=tag_starts.get) == 'X', \"Hmmm...'X' is expected to be the least common starting bigram.\"\n",
    "assert max(tag_starts, key=tag_starts.get) == 'DET', \"Hmmm...'DET' is expected to be the most common starting bigram.\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your starting tag counts look good!</div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPLEMENTATION: Sequence Ending Counts\n",
    "Complete the function below to estimate the bigram probabilities of a sequence ending with each tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your ending tag counts look good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ending_counts(sequences):\n",
    "    \"\"\"Return a dictionary keyed to each unique value in the input sequences list\n",
    "    that counts the number of occurrences where that value is at the end of\n",
    "    a sequence.\n",
    "    \n",
    "    For example, if 18 sequences end with DET, then you should return a\n",
    "    dictionary such that your_starting_counts[DET] == 18\n",
    "    \"\"\"\n",
    "    ending_counts = {}\n",
    "    \n",
    "    for i, sentence in enumerate(sequences):\n",
    "        indexVal = len(sentence) -1\n",
    "        if sentence[indexVal] in ending_counts:\n",
    "            ending_counts[sentence[indexVal]] += 1\n",
    "        else:\n",
    "            ending_counts[sentence[indexVal]] = 1\n",
    "    \n",
    "    return ending_counts\n",
    "\n",
    "# TODO: Calculate the count of each tag ending a sequence\n",
    "tag_ends = ending_counts(data.training_set.Y)\n",
    "\n",
    "assert len(tag_ends) == 12, \"Uh oh. There should be 12 tags in your dictionary.\"\n",
    "assert min(tag_ends, key=tag_ends.get) in ['X', 'CONJ'], \"Hmmm...'X' or 'CONJ' should be the least common ending bigram.\"\n",
    "assert max(tag_ends, key=tag_ends.get) == '.', \"Hmmm...'.' is expected to be the most common ending bigram.\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your ending tag counts look good!</div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPLEMENTATION: Basic HMM Tagger\n",
    "Use the tag unigrams and bigrams calculated above to construct a hidden Markov tagger.\n",
    "\n",
    "- Add one state per tag\n",
    "    - The emission distribution at each state should be estimated with the formula: $P(w|t) = \\frac{C(t, w)}{C(t)}$\n",
    "- Add an edge from the starting state `basic_model.start` to each tag\n",
    "    - The transition probability should be estimated with the formula: $P(t|start) = \\frac{C(start, t)}{C(start)}$\n",
    "- Add an edge from each tag to the end state `basic_model.end`\n",
    "    - The transition probability should be estimated with the formula: $P(end|t) = \\frac{C(t, end)}{C(t)}$\n",
    "- Add an edge between _every_ pair of tags\n",
    "    - The transition probability should be estimated with the formula: $P(t_2|t_1) = \\frac{C(t_1, t_2)}{C(t_1)}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your HMM network topology looks good!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_model = HiddenMarkovModel(name=\"base-hmm-tagger\")\n",
    "\n",
    "states = {}\n",
    "\n",
    "for tag in emission_counts:\n",
    "    prob_dct = {}\n",
    "    total = tag_unigrams[tag]\n",
    "    prob_dist = {key: value / total for key, value in emission_counts[tag].items()}\n",
    "    \n",
    "    tag_distribution = DiscreteDistribution(prob_dist)\n",
    "    temp_state = State(tag_distribution, name=tag)\n",
    "    states[tag] = temp_state\n",
    "    \n",
    "    basic_model.add_state(states[tag])\n",
    "    \n",
    "for bigram in tag_bigrams.keys():\n",
    "    \n",
    "    len_data_y = len(data.training_set.Y)\n",
    "    b0 = bigram[0]\n",
    "    b1 = bigram[1]\n",
    "    \n",
    "    prob =  tag_starts[b0] / len_data_y\n",
    "    basic_model.add_transition(basic_model.start, states[b0], prob)\n",
    "    \n",
    "    prob = tag_bigrams[bigram] / tag_unigrams[b0] \n",
    "    basic_model.add_transition(states[b0], states[b1], prob)\n",
    "    \n",
    "\n",
    "    prob = tag_ends[b0] / len_data_y\n",
    "    basic_model.add_transition(states[b0], basic_model.end, prob)\n",
    "\n",
    "basic_model.bake()\n",
    "\n",
    "\n",
    "\n",
    "assert all(tag in set(s.name for s in basic_model.states) for tag in data.training_set.tagset), \\\n",
    "       \"Every state in your network should use the name of the associated tag, which must be one of the training set tags.\"\n",
    "assert basic_model.edge_count() == 168, \\\n",
    "       (\"Your network should have an edge from the start node to each state, one edge between every \" +\n",
    "        \"pair of tags (states), and an edge from each state to the end node.\")\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your HMM network topology looks good!</div>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy basic hmm model: 97.54%\n",
      "testing accuracy basic hmm model: 95.96%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"alert alert-block alert-success\">Your HMM tagger accuracy looks correct!</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmm_training_acc = accuracy(data.training_set.X, data.training_set.Y, basic_model)\n",
    "print(\"training accuracy basic hmm model: {:.2f}%\".format(100 * hmm_training_acc))\n",
    "\n",
    "hmm_testing_acc = accuracy(data.testing_set.X, data.testing_set.Y, basic_model)\n",
    "print(\"testing accuracy basic hmm model: {:.2f}%\".format(100 * hmm_testing_acc))\n",
    "\n",
    "assert hmm_training_acc > 0.97, \"Uh oh. Your HMM accuracy on the training set doesn't look right.\"\n",
    "assert hmm_testing_acc > 0.955, \"Uh oh. Your HMM accuracy on the testing set doesn't look right.\"\n",
    "HTML('<div class=\"alert alert-block alert-success\">Your HMM tagger accuracy looks correct!</div>')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Decoding Sequences with the HMM Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Key: b100-28144\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('CONJ', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'NOUN', 'NUM', '.', 'CONJ', 'NOUN', 'NUM', '.', '.', 'NOUN', '.', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-23146\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('PRON', 'VERB', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', 'NOUN', 'VERB', 'VERB', '.', 'ADP', 'VERB', 'DET', 'NOUN', 'ADP', 'NOUN', 'ADP', 'DET', 'NOUN', '.')\n",
      "\n",
      "\n",
      "Sentence Key: b100-35462\n",
      "\n",
      "Predicted labels:\n",
      "-----------------\n",
      "['DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.']\n",
      "\n",
      "Actual labels:\n",
      "--------------\n",
      "('DET', 'ADJ', 'NOUN', 'VERB', 'VERB', 'VERB', 'ADP', 'DET', 'ADJ', 'ADJ', 'NOUN', 'ADP', 'DET', 'ADJ', 'NOUN', '.', 'ADP', 'ADJ', 'NOUN', '.', 'CONJ', 'ADP', 'DET', 'NOUN', 'ADP', 'ADJ', 'ADJ', '.', 'ADJ', '.', 'CONJ', 'ADJ', 'NOUN', 'ADP', 'ADJ', 'NOUN', '.')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in data.testing_set.keys[:3]:\n",
    "    print(\"Sentence Key: {}\\n\".format(key))\n",
    "    print(\"Predicted labels:\\n-----------------\")\n",
    "    print(simplify_decoding(data.sentences[key].words, basic_model))\n",
    "    print()\n",
    "    print(\"Actual labels:\\n--------------\")\n",
    "    print(data.sentences[key].tags)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
